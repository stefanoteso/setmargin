%%%% ijcai16.tex

\typeout{Constructive Preference Elicitation by Setwise Max-margin Learning}

\documentclass{article}
\usepackage{ijcai16}
\usepackage{times}
%\usepackage{latexsym}
\usepackage{graphicx}

\RequirePackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}

% ---------------------------------------------------------------------------

\algrenewcommand{\algorithmicrequire}{\textbf{Input:}}
\algrenewcommand{\algorithmicensure}{\textbf{Output:}}

\renewcommand\[{\begin{equation}}
\renewcommand\]{\end{equation}}

% Bold math symbols
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\bbB}{\mathbb{B}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbD}{\mathbb{D}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbG}{\mathbb{G}}
\newcommand{\bbH}{\mathbb{H}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbJ}{\mathbb{J}}
\newcommand{\bbK}{\mathbb{K}}
\newcommand{\bbL}{\mathbb{L}}
\newcommand{\bbM}{\mathbb{M}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbO}{\mathbb{O}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\bbT}{\mathbb{T}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbV}{\mathbb{V}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbY}{\mathbb{Y}}
\newcommand{\bbZ}{\mathbb{Z}}

% Calligraphic math symbols
\newcommand{\calvar}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\calA}{\calvar{A}}
\newcommand{\calB}{\calvar{B}}
\newcommand{\calC}{\calvar{C}}
\newcommand{\calD}{\calvar{D}}
\newcommand{\calE}{\calvar{E}}
\newcommand{\calF}{\calvar{F}}
\newcommand{\calG}{\calvar{G}}
\newcommand{\calH}{\calvar{H}}
\newcommand{\calI}{\calvar{I}}
\newcommand{\calJ}{\calvar{J}}
\newcommand{\calK}{\calvar{K}}
\newcommand{\calL}{\calvar{L}}
\newcommand{\calM}{\calvar{M}}
\newcommand{\calN}{\calvar{N}}
\newcommand{\calO}{\calvar{O}}
\newcommand{\calP}{\calvar{P}}
\newcommand{\calQ}{\calvar{Q}}
\newcommand{\calR}{\calvar{R}}
\newcommand{\calS}{\calvar{S}}
\newcommand{\calT}{\calvar{T}}
\newcommand{\calU}{\calvar{U}}
\newcommand{\calV}{\calvar{V}}
\newcommand{\calW}{\calvar{W}}
\newcommand{\calX}{\calvar{X}}
\newcommand{\calY}{\calvar{Y}}
\newcommand{\calZ}{\calvar{Z}}

% Vectors
\newcommand{\vecvar}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\va}{\vecvar{a}}
\newcommand{\vb}{\vecvar{b}}
\newcommand{\vc}{\vecvar{c}}
\newcommand{\vd}{\vecvar{d}}
\newcommand{\ve}{\vecvar{e}}
\newcommand{\vf}{\vecvar{f}}
\newcommand{\vg}{\vecvar{g}}
\newcommand{\vh}{\vecvar{h}}
\newcommand{\vi}{\vecvar{i}}
\newcommand{\vj}{\vecvar{j}}
\newcommand{\vk}{\vecvar{k}}
\newcommand{\vl}{\vecvar{l}}
\newcommand{\vm}{\vecvar{m}}
\newcommand{\vn}{\vecvar{n}}
\newcommand{\vo}{\vecvar{o}}
\newcommand{\vp}{\vecvar{p}}
\newcommand{\vq}{\vecvar{q}}
\newcommand{\vr}{\vecvar{r}}
\newcommand{\vs}{\vecvar{s}}
\newcommand{\vt}{\vecvar{t}}
\newcommand{\vu}{\vecvar{u}}
\newcommand{\vv}{\vecvar{v}}
\newcommand{\vw}{\vecvar{w}}
\newcommand{\vx}{\vecvar{x}}
\newcommand{\vy}{\vecvar{y}}
\newcommand{\vz}{\vecvar{z}}
\newcommand{\valpha}{\vecvar{\alpha}}
\newcommand{\veps}{\vecvar{\varepsilon}}
\newcommand{\vphi}{\vecvar{\varphi}}
\newcommand{\vpsi}{\vecvar{\psi}}
\newcommand{\vtheta}{\vecvar{\theta}}

% Operators
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

% Debugging

\usepackage{color}
\newcommand{\andrea}[1]{{\bf \textcolor{blue}{{\fbox{Andrea:} #1}}}}
\newcommand{\stefano}[1]{{\bf \textcolor{green}{{\fbox{Stefano:} #1}}}}
\newcommand{\paolo}[1]{{\bf \textcolor{red}{{\fbox{Paolo:} #1}}}}

% ---------------------------------------------------------------------------

\title{Constructive Preference Elicitation by Setwise Max-margin Learning} %with?
\author{ID xxxx}

\begin{document}

\maketitle

\begin{abstract}
In this paper we propose an approach to preference elicitation that is suitable to large
configuration problem domains where stated preferences can be noisy.
Our setwise max-margin method can be viewed as a generalization of max-margin learning to sets,
and can produce a set of ``diverse'' items that can be used to ask informative queries to the user.
Moreover, the approach can encourage sparsity in the parameter space, in order to favor the assessment of utility towards combinations of weights that concentrate on just few features.
We present an optimization formulation and show, with simulations, how our approach is able to efficiently elicit the user's utility function even in very large datasets.


\end{abstract}

\section{Introduction}

Preferences \cite{Peintner2008} play an important role in artificial intelligence,
including fields spanning from recommender systems to automatic planning, 
from non monotonic reasoning to computational social choice and algorithmic decision theory.
The task of eliciting or learning preferences is therefore a crucial; typically only limited information about the user's preferences will be available and the cost of obtaining additional preference information will be usually high (from a cognitive and/or computational point of view).
The goal in preference elicitation is that of gaining enough information about the user's preferences (typically represented by an utility function $u$, unknown to the system) in order to recommend a decision or a course of action.

The assessment of preferences have received considerable attention in the literature, with early works confined to the operation research and management literature mostly \cite{}.
In the past decade a number of researchers have considered elicitation of preferences from an artificial intelligence perspective; within the machine learning field the term preference learning has been catching up.
While preferences are often assessed using some ad-hoc rules \cite{},
recently a number of researchers have proposed principled methods that elicit utility in an adaptive way \cite{chajewska2000,boutilier2002,Wang2003,boutilier2006,braziunas-mmr:uai07,guo2010real,viappiani2010optimal}; the aims is that of focusing on learning the ``important'' part of the utility, allowing to recommend good (or even optimal) decision with only a partial information about the utility function.

%One option is to be Bayesian and to maintain a probability distribution over the possible realizations of the utility's parameters \cite{chajewska2000,boutilier2002,guo2010real,viappiani2010optimal}.
%Alternatively, when distribution information about the parameters is not available, one can reason about all feasible utility functions consistent with the currently known information about the user; from the user's response we are able to infer constraints on the parameters implicated in the utility model \cite{Wang2003,boutilier2006,braziunasmmr:uai07,viappiani2009}.
%This latter approach has also the advantage of avoiding the computationally demanding task of maintaining distribution information and performing Bayesian updates.

% constructive preference elicitation
While most works assume that items or decisions are available in a (possibly large)
dataset, in this paper we propose an adaptive elicitation framework that takes a {\em constructive} view on preference
elicitation, enlarging its scope from the selection of items among a
set of candidates to the synthesis of entirely novelinstances. 
Instances are solutions to a given optimization problem; they are represented as combinations of basic elements
(e.g. the components of a laptop) subject to a set of constraints
(e.g. the laptop model determines the set of available CPUs). 
A utility function is learned over the feature representation of an
instance, as customary in many preference elicitation approaches. 
The recommendation is then made by solving a constrained optimization
 problem in the space of feasible instances, guided by the learned
utility. 

Our approach is related to \cite{boutilier2006}, where minimax regret is used both
as a robust recommendation criterion and as a technique to drive elicitation in configuration problems.
The main limitation of the minimax regret approach is the lack of tolerance with respect to user inconsistency (the user might state that item x is preferred to y, even though the latter has higher utility).

% setwise max-margin formulation to deal with uncertainty in user utility
Indeed, learning a user utility function requires setting a preference
elicitation strategy and dealing with uncertain and possibly
inconsistent user feedback. 
Bayesian preference elicitation approaches
deal with both problems by building a probability distribution on
candidate functions (endowed with a response or error model to be used for inference) and asking queries maximizing informativeness
measures such as expected value of information (EVOI)~\cite{chajewska2000,viappiani2010optimal}. 

These
approaches are however computationally expensive and can not scale to
fully constructive scenarios, as shown in our experimental results.
We take a space decomposition perspective and jointly learn a set of
weight vectors, each representing a candidate utility function,
maximizing diversity between the vectors and consistency with the
available feedback. These two conflicting objectives tend to generate
equally plausible alternative hypotheses for the unknown
utility. 
Our approach to preference elicitation works by combining weight vector
learning with instance generation, so that each iteration of the
algorithm produces two outcomes: a set of weight vectors and a set of
instances, each maximizing its score according to one of the weight
vectors. 

We evaluate the effectiveness of our approach by testing our elicitation method
in both synthetic and configuration problems, and comparing it to state-of-the-art
methods.

The paper is structured as follows: after discussing related works in next Section,
we present some brackground material in Section \ref{sec:background} 
and then proceed to our setwise maxmargin method in Section \ref{sec:formulation}; 
we discuss experimental results in Section \ref{sec:experiments}
and conclude with final remarks (Section \ref{sec:conclusions}).

%\section{Related Work}

%Preference elicitation for the customization of user interfaces \cite{gajos2005}.

%WRITEME

\section{Background}
\label{sec:background}
%\section{Preference Elicitation}

\paragraph{Notation.} We use boldface letters $\vx$ to indicate vectors,
uppercase letters $X$ for matrices, and calligraphic capital letters $\calX$
for sets. We frequently abbreviate the set $\{ x^i \}_{i=1}^n$ as $\{ x^i \}$
whenever the range of the index $i$ is clear from the context, and use $[n]$ as
a shorthand for the set $\{1, \ldots, n\}$. We write $\|\vx\|_1 := \sum_z |x_z|$
to indicate the $\ell_1$ vector norm, $\langle \cdot, \cdot \rangle$ to
denote the usual dot product, and $X'$ to denote matrix transposition.

\paragraph{Setting.} We assume to have a multi-attribute feature space
$\calX$ of configurations $\vx = (x_1, \ldots, x_m)$ over $m$
features. For the sake of simplicity we focus on binary features only,
i.e. $x_z\in\{0,1\}$ for all $z\in[m]$, assuming a one-hot encoding of
categorical features. This is a common choice for preference
elicitation methods~\cite{guo2010real,viappiani2010optimal}. Support
for linearly dependent continuous features will be discussed later on.

We further assume that the set of {\em feasible} configurations, denoted by
$\calX_\text{feasible}$, is expressed as
a conjunction of linear constraints. This allows to formulate both arithmetic
and logical constraints,
e.g. under the canonical mapping of $True$ to $1$ and $False$ to $0$, the
Boolean disjunction of two binary variables $x_1 \lor x_2$ can be rewritten as
$x_1 + x_2 \ge 1$.

Consistently with previous work~\cite{guo2010real,viappiani2010optimal}, we model users by means
of linear utility functions: the user's preferences are represented by a weight
vector $\vw\in\bbR^m$, and the utility of a configuration $\vx$ is given by
$\langle \vw, \vx \rangle = \sum_{z=1}^m w_z x_z$. In the remainder of the paper we
require all weights to be {\em non-negative} and {\em bounded}: the per-attribute
weights $w_z$ must lie in a (constant but otherwise arbitrary) interval
$[w^\bot_z, w^\top_z]$, with $w^\bot_z \ge 0$. Both requirements are quite
natural, and enable the translation of our core optimization problem into a
mixed-integer linear problem (as done in Section~\ref{sec:formulation}).

During learning, the actual weight vector $\vw$ is {\em unknown} to the
learning system, and must be estimated from pairwise choices elicited from the
user.

%\andrea{@PAOLO: qualche parola e reference per giustificare la scelta di pairwise queries?}  
Comparison queries are especially natural, asking a user if she prefers one option x to another y;
these comparisons can be extended to choice sets of more than two options \cite{viappiani2009,viappiani2010optimal}.
Comparison and choice queries are common in conjoint analysis \cite{louviere2000,toubia2004}.


We consider three possible outcomes for a pairwise comparison between
two configurations $\vx$ and $\vx'$: either $\vx$ is preferred to $\vx'$ (written
$\vx \succ \vx'$), $\vx'$ is preferred to $\vx$ ($\vx \prec \vx'$), or there is
no clear preference between the two items ($\vx \approx \vx'$). We write
$\calD$ to denote the set of preferences (answers to comparison queries) 
elicited from the user. Queries are typically selected so as to maximize 
some measure of informativeness of the
resulting responses.  Details on our actual query selection strategy will be
provided in Section~\ref{sec:formulation}.

\section{Setwise Max-margin Learning}
\label{sec:formulation}

\paragraph{Non-linear Formulation.} We first introduce the problem
formulation as a mixed integer non-linear optimization problem, and
then show how to reduce it to a mixed integer linear optimization one.

The goal of our setwise max-margin approach is twofold. First, for any
given set size $k\geq 1$, we want to find a {\em set} of $k$ weight
vectors $\vw^{1}, \ldots, \vw^{k}$, chosen so that all user-provided
preferences are satisfied by the largest possible margin (i.e. all
weight vectors are consistent with respect to the user responses
$\calD$, modulo inconsistencies) and so that they are maximally
diverse.  Second, we want to construct a {\em set} of $k$
configurations $\vx^{1}, \ldots, \vx^{k}$, so that each configuration
$\vx^{i}$ is the ``best'' possref:keeney-mautible option when evaluated according to
the corresponding $\vw^{i}$ and configurations are maximally diverse
among each other. These options will be later employed to formulate
the user queries.

The first goal is achieved by translating all pairwise preferences
$\calD$ into ranking constraints: preferences of the form
$\vy^h_+ \succ \vy^h_-$ become linear inequalities of the form
$\langle \vw^i, \vy^h_+ - \vy^h_- \rangle \geq \mu$, where $\mu$ is the
{\em margin} variable (which we aim at maximizing) and $h$ ranges over
the responses.  Non-separable datasets, which occur in practice due to
occasional inconsistencies in user feedback, are handled by
introducing slack variables (whose sum we aim at minimizing). When
augmented with the slacks, the above inequalities take the form:
%
$$ \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge \mu - \varepsilon^{i}_h $$
%
where $\varepsilon^{i}_h$ is the penalty incurred by weight vector $\vw^{i}$
for violating the margin separation of pair $h$. Indifference preferences, i.e.
$\vy^h_1 \approx \vy^h_2$, are translated as $|\langle \vw^i, \vy^h_1 - \vy^h_2 \rangle| < \varepsilon^i_h$;
the slack increases with the difference between the estimated utility of the
two options.

The second goal requires to jointly maximize the utility of each
$\vx^{i}$ according to its corresponding weight vector $\vw^i$ and its
scoring difference with respect to the other configurations $\vx^j$ in
the set. We achieve this by maximizing the sum of utilities
$\sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle$ and adding ranking
constraints of the form
$\langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \geq \mu$ for all
$i,j\in[k]$, $i \ne j$.


% Ideally, the second goal would be implemented as:
% %
% $$ \vx^{i} = \argmax_{\vx \in \calX_\text{feasible}} \langle \vw^{i}, \vx^{i} \rangle $$
% %
% However this formulation is highly impractical. We therefore only require 
% each option $\vx^{i}$ to be the best {\em among} the configurations
% $\{ \vx^i \}$. This can be accomplished by imposing
% constraints of the form $\langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \geq \mu$
% for all $i,j\in[k]$, $i \ne j$.
% This however does not guarantee that the produced $\{ \vx^{i} \}$ have a high
% {\em absolute} utility. We therefore favor high-quality configurations by
% introducing an additional term $\sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle$
% in the objective function.

A straightforward encoding of the above desiderata leads to the
following mixed integer {\em non-linear} optimization problem over the
variables $\mu \in \bbR$, $\{ \vw^i \in \bbR^m \}$, $\{ \vx^i \in \{0,1\}^m \}$:
%
{\footnotesize
\begin{align}
    \max
        & \;\; \mu - \alpha \sum_{i=1}^k \| \veps^{i} \|_1 - \beta \sum_{i=1}^k \| \vw^{i} \|_1 + \gamma \sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle
        \nonumber
    \\
    \text{s.t.}
        & \;\; \forall \; i \in [k], \forall \; h \in [n] \nonumber
    \\
        & \;\; \qquad \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge \mu - \varepsilon^{i}_h \label{eq:wyconstr}
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \quad \langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \ge \mu \label{eq:wxconstr}
    \\
        & \;\; \forall \; i \in [k] \quad \vw^\bot \le \vw^{i} \le \vw^\top \label{eq:wbounds}
    \\
        & \;\; \forall \; i \in [k] \quad \vx^{i} \in \calX_{\text{feasible}} \label{eq:xbounds}
    \\
        & \;\; \forall \; i \in [k] \quad \veps^{i} \ge 0 \nonumber
    \\
        & \;\; \mu \ge 0 \nonumber
\end{align}
}
%
Let us illustrate the above piece by piece. The objective is composed of four
parts: we maximize the shared margin $\mu$ (first part) and minimize the total
sum of the ranking errors $\veps^i$ incurred by each weight vector $\vw^{i}$
(second part), while at the same time regularizing the magnitude of the
weights (third part) and the quality of the configurations $\{ \vx^{i} \}$ (last
part). The non-negative hyperparameters $\alpha,\beta,\gamma$ control the
influence of the various components.

The third part of the objective does require a more in depth explanation. In
many scenarios the user will have strong preferences about some attributes, but
will be indifferent to most of them~\cite{} \stefano{@Paolo: add refs}. The $\ell_1$ penalty is frequently
used to improve the sparsity of learned models~\cite{lasso,zhang2008,Hensinger2010}, with consequent gains
in generalization ability and efficiency, as confirmed by our empirical
findings (see Section~\ref{sec:experiments}).

The two core constraints are Equations~(\ref{eq:wyconstr}) and~(\ref{eq:wxconstr}),
which are taken directly from the discussion above. The former enforces the
correct ranking of the observed user preferences, while the latter ensures that
the generated configurations are diverse in terms of the weight vectors they
maximize. Equations~(\ref{eq:wbounds}) and~(\ref{eq:xbounds})
ensure that the weights and configurations are in fact feasible, while the
remaining two guarantee the non-negativity of the slack and margin variables.
Since we require $\vw^\bot \ge 0$, Eq.~(\ref{eq:wbounds}) also enforces the
weights to be non-negative.

Note that we are choosing the configurations $\{ \vx^i \}$ and the weight vectors $\{
\vw^i \}$ {\em simultaneously}. Since we maximize the margin $\mu$, the optimizer
will prefer a set of configurations $\{ \vx^{i} \}$ that partitions the weight space
roughly equally, and corresponding utility functions such that each $\vw^{i}$
lies (intuitively) close to the centre of each subregion. See
Figure~\ref{fig:setmargin} for a depiction of this intuition.\andrea{@Paolo: mmh non chiarissimo, da rivedere insieme, legenda inclusa}

\begin{figure}[t]
    \begin{center}
        \includegraphics[width=16em]{figures/setmargin}
    \end{center}
    \caption{\label{fig:setmargin} The intuition behind setwise max-margin; the red points are utilty vectors $\vw^{i}$ $\vw^{j}$, the red line corresponds to the constraint $\langle \vw, \vx^{1} - \vx^{2} \rangle \ge 0$.}
\end{figure}

\paragraph{MILP Formulation.} This initial formulation is problematic to solve,
as Eq.~(\ref{eq:wxconstr}) involves quadratic terms over mixed continuous integer variables. 
Here we show how to reformulate the
problem as a mixed integer linear program (MILP). Our goal is to
replace Eq.~(\ref{eq:wxconstr}) with a set of linear constraints through
a suitable variable transformation.

In order to do so, we introduce a set of fresh variables $p^{i,j}_z$ for every
$i,j\in[k]$ and $z\in[m]$. Assuming for the time being that the new variables
do satisfy the equation $p^{i,j}_z = w^i_z x^j_z$, we rewrite the fourth
component of the objective function in terms of the new variables as:
%
$$ \gamma \sum_{i=1}^k \sum_{z=1}^m p^{i,i}_z $$
%
and, similarly, Eq.~(\ref{eq:wxconstr}) as:
%
\[ \forall \; i, j \in [k], i \neq j \;.\; \sum_{z=1}^m p^{i,i}_z - p^{i,j}_z \ge \mu \label{eq:pxconstr} \]
%
The fact that $p^{i,j}_z = w^{i}_z x^{j}_z$ is achieved by
setting the following additional constraints. We distinguish between two cases:
(i) $p^{i,i}_z$ and (ii) $p^{i,j}_z$ for $i \ne j$.  Recall that we are
maximizing the margin $\mu$. Now, due to Eq.~(\ref{eq:pxconstr}), the optimizer will
try to keep $p^{i,i}_z$ as large as possible and $p^{i,j}_z$ as small as
possible.

(Case i) We add an explicit upper bound:
%
$$ p^{i,i}_z \le \min \{ w_\text{max} x^{i}_z, w^{i}_z \} $$
%
where $w_\text{max}$ is a sufficiently large constant.
On one hand, if $x^i_z = 0$ the product $w^i_z x^i_z$ evaluates to $0$, and so does
the upper bound $w_\text{max} x^{i}_z = 0$. On the other hand, if $x^i_z=1$
then the product $w^i_z x^i_z$ amounts to $w^i_z$, while the upper
bound reduces to $\min \{ w_\text{max}, w^{i}_z \}$. By taking a sufficiently
large constant $w_\text{max}$ (e.g. $w_\text{max} := \max_z w^\top_z$) the
upper bound simplifies to $w^i_z$. Since $p^{i,i}_z$ is being maximized, in
both cases it will attain the upper bound, and thus satisfy $p^{i,j}_z = w^i_z x^i_z$.

(Case ii) We add an explicit lower bound:
%
$$ p^{i,j}_z \ge \max \{ 0, w^{i}_z - w_\text{max}(1 - x^{j}_z) \} $$
%
If $x^j_z = 1$ the lower bound simplifies to $\max \{ 0, w^{i}_z \} = w^{i}_z$,
due to the non-negativity of $w^i_z$. Otherwise, if $x^j_z = 0$
then the lower bound becomes $\max \{ 0, w^{i}_z - w_\text{max} \}$, where
the second term is at most $0$. Since $p^{i,j}_z$ is being minimized, in both
cases it will attain the lower bound, and thus satisfy $p^{i,j}_z = w^i_z
x^j_z$.\footnote{Since $\mu$ is upper-bounded by Eq.~(\ref{eq:wyconstr}), in some
cases the $p^{i,j}_z$ variables do not attain the lower bound. As a
consequence, the MILP reformulation of Eq.~(\ref{eq:wxconstr}) is a (tight)
approximation of the original one. This has no impact on the quality of the
solutions.}

Substituting the above MILP constraints into the original non-linear
formulation, we obtain the following mixed-integer linear problem:
%
{\footnotesize
\begin{align}
    \max
        & \;\; \mu - \alpha \sum_{i=1}^k \| \veps^{i} \|_1 - \beta \sum_{i=1}^k \| \vw^{i} \|_1 + \gamma \sum_{i=1}^k \sum_{z=1}^m p^{i,i}_z
        \nonumber
    \\
    \text{s.t.}
        & \;\; \forall \; i \in [k], \forall \; h \in [n] \nonumber
    \\
        & \;\; \qquad \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge \mu - \varepsilon^{i}_h \nonumber
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \quad \sum_{z=1}^m p^{i,i}_z - p^{i,j}_z \ge \mu
    \\
    %     & \;\; \forall \; i \in [k], \forall \; z \in [m] \nonumber
    % \\
        & \;\; \forall \; i, j \in [k], i \neq j, \forall \; z \in [m] \nonumber
    \\
        & \;\; \qquad p^{i,i}_z \le \min \{ w_\text{max} x^{i}_z, w^{i}_z \}
    \\
        & \;\; \qquad p^{i,j}_z \ge \max \{ 0, w^{i}_z - w_\text{max}(1 - x^{j}_z) \}
    \\
        & \;\; \forall \; i \in [k] \quad \vw^\bot \le \vw^{i} \le \vw^\top \label{eq:wbounds2}
    \\
        & \;\; \forall \; i \in [k] \quad \vx^{i} \in \calX_{\text{feasible}} \nonumber
    \\
        & \;\; \forall \; i \in [k] \quad \veps^{i}_h \ge 0 \nonumber
    \\
        & \;\; \mu \ge 0 \nonumber
\end{align}
}
%
which can be solved by any suitable MILP solver.

\paragraph{Set-wise max-margin.} The full {\sc SetMargin} algorithm
follows the usual preference elicitation loop. Starting from an
initially empty set of user responses $\calD$, it repeatedly solves
the MILP problem above using the set $\calD$ to enforce ranking
constraints on the weight vectors $\{\vw^i\}$. The generated
configurations $\{\vx^i\}$, which are chosen to be as good as possible
with respect to the estimated user preferences, and as diverse as
possible, are then employed to formulate a set of user queries. The
new replies are added to $\calD$ and the whole procedure is
repeated. The algorithm terminates after a fixed number of iterations,
or once another suitable condition is met. \andrea{@Paolo: what termination
condition for pref elicitation?}  
Termination might be left to the user to decide (see for example \ref{} for discussion on user-involved recommender systems); the system can however propose
to terminate when the difference between the utility weights is small enough.

The procedure is sketched in
Algorithm~\ref{alg:setmargin}. Note that at the end of the preference
elicitation procedure, a final recommendation is made by solving the
MILP problem for $k=1$.

\begin{algorithm}
{\footnotesize
\begin{algorithmic}[1]
    \Procedure{SetMargin}{$k, \alpha, \beta, \gamma, T$}
        \State $\calD \gets \emptyset$
        \For{$t = 1, \ldots, T$}
            \State \{$\vw^{i}, \vx^{i}\}_{i=1}^k \gets \text{{\sc Solve}}(\calD, k, \alpha, \beta, \gamma)$
            \For{$\vx^{i},\vx^{j} \in \{ \vx^{1}, \ldots, \vx^{k} \} \; \text{{\bf s.t.}} \; i < j$}
                \State $\calD \gets \calD \cup \text{{\sc QueryUser}}(\vx^{i},\vx^{j})$
            \EndFor
        \EndFor
        \State $\vw^*, \vx^* \gets \text{{\sc Solve}}(\calD, 1, \alpha, \beta, \gamma)$
        \State ${\bf return}\; \vw^*, \vx^*$
    \EndProcedure
\end{algorithmic}
}
\caption{\label{alg:setmargin} The {\sc SetMargin} algorithm. Here $k$ is the
set size, $\alpha,\beta,\gamma$ are the hyperparameters, and $T$ is the maximum
number of iterations. The values of $\calX_\text{feasible}$, $\vw^\top$ and
$\vw^\bot$ are left implicit.}
\end{algorithm}

\paragraph{Linearly dependent real attributes.} In many domains of interest,
items are composed of both Boolean and real-valued attributes, where the latter
depend linearly  on the former. This is for instance the case for the price,
weight and power consumption of a laptop model, which depend linearly on the
choice of components.
%
In this setting, item configurations are composed of two parts: $\vx =
(\vx_B;\vx_R)$, where $\vx_B$ is Boolean and $\vx_R$ is real-valued, and the
relation between the two is entirely described by an appropriately sized
non-negative cost matrix $C$, such that $\vx_R = C \vx_B$. It is
straightforward to extend the MILP formulation to this setting, as follows.

First, we rewrite the weight vector as $\vw = (\vw_B;\vw_R)$. The utility
becomes:
%
$$ \langle \vw, \vx \rangle = \langle \vw_B, \vx_B \rangle + \langle \vw_R, C \vx_B \rangle = \langle \vw_B + C' \vw_R, \vx_B \rangle $$
%
The generalized problem is obtained by substituting $\vw^i$ with $\vv^i :=
\vw_B^i + C' \vw_R^i$.  All constraints remain the same. The only notable
change occurs in Eq.~(\ref{eq:wbounds2}), which becomes:
%
$$ \forall \; i \in [k] \;.\; (\vw_B^\bot + C' \vw_R^\bot) \le \vv^i \le (\vw_B^\top + C' \vw_R^\top)$$
%
As can be seen, non-negativity of $C$ is required for the weights $\{\vv^i\}$
to be non-negative.

\section{Experiments}
\label{sec:experiments}

We implemented the {\sc SetMargin} algorithm using Python, leveraging Gurobi
6.5.0 for solving the core MILP problem. Both the {\sc SetMargin} source code
and the full experimental setup are available at {\tt https://db.tt/oqY62odW}.

We compare {\sc SetMargin} against two strong Bayesian baselines:
\cite{guo2010real} and \cite{viappiani2010optimal}.
\stefano{Paolo, could you describe the baselines?}

We adopt the {\em indifference-augmented} Bradley-Terry user response
model introduced in~\cite{guo2010real}. According to the classical
(without indifference) Bradley-Terry model~\cite{BraTer52}, when queried about a pair
of configurations, the probability that a user will prefer
configuration $\vx^i$ over the alternative $\vx^j$ amounts to:

%
$$ (1 + \exp(-\lambda_1 \langle\vw,\vx^i - \vx^j\rangle))^{-1} $$
%
where $\vw$ is the weight vector of the true underlying user utility.
In other words, the probability grows with the difference between the
utilities of the two items. Support for indifference has been
introduced in~\cite{guo2010real} by postulating that the probability
of the user being indifferent about the two configurations depends on
how close their utilities are, as in:
%
$$ \exp(\lambda_2 |\langle\vw,\vx^i - \vx^j\rangle|) $$
%
The parameters $\lambda_1$ and $\lambda_2$ were set to one for all
simulations, as in~\cite{guo2010real}.

In all experiments we use an internal 5-fold cross-validation procedure to
update the hyperparameters $\alpha$, $\beta$, and $\gamma$ after every 5
iterations. The hyperparameters are chosen as to minimize the ranking loss over
the user responses collected so far. $\alpha$ is taken in $\{20, 10, 5, 1\}$,
while $\beta$ and $\gamma$ are taken in $\{10, 1, 0.1, 0.001\}$.\footnote{Note
that $\alpha$ can not be taken to be less than $1$, as in this case, the
objective can be increased arbitrarily while keeping the right-hand side of
Eq.~(\ref{eq:wyconstr}) constant, rendering the problem unbounded.}

\paragraph{Synthetic Dataset.} Following the experimental protocol
in~\cite{guo2010real} and \cite{viappiani2010optimal}, in the first
experiment we evaluate the behavior of the proposed method in an
artificial setting with increasingly complex problems. We developed
synthetic datasets with $r$ attributes, for increasing values of $r$.
Each attribute takes one of $r$ possible values, so that the one-hot
encoding of attributes results in $m=r^2$ features. In terms of space
of configurations, for $r=3$ the synthetic dataset corresponds to 
$\calX_\text{feasible} = [3] \times [3] \times [3]$, for $r=4$ to
$\calX_\text{feasible} = [4] \times [4] \times [4] \times [4]$, and so on. The
cardinality of $\calX_\text{feasible}$ is $r^r$, and grows (super)
exponentially with $r$.
% We developed
% seven synthetic datasets: each dataset involves $m=2,\ldots,7$
% attributes, where each attribute takes one of $m$ possible
% values. More explicitly, for $m=2$ the synthetic dataset is
% $\calX_\text{feasible} = [2] \times [2]$, for $m=3$ to
% $\calX_\text{feasible} = [3] \times [3] \times [3]$, and so on. The
% cardinality of $\calX_\text{feasible}$ is $m^m$, and grows (super)
% exponentially with $m$. 
For $r=3$, the dataset is comparable to the synthetic one used
in~\cite{guo2010real} and~\cite{viappiani2010optimal}, which have
three attributes with 2, 2 and 5 values respectively, for a total of
20 feasible configurations.  For larger $r$ the size of the space
grows much larger than the one typically used in the Bayesian
preference elicitation literature, and as such represents a good test
bed for comparing the scalability of the various methods. The feasible
configuration space was encoded in {\sc SetMargin} through appropriate
MILP constraints, while the other methods require all datasets to be
explicitly grounded.

Users were simulated by drawing $20$ random utility vectors from each of four
different distributions. The first two mimic those used
in~\cite{guo2010real}\footnote{The normal distribution reported
in~\cite{guo2010real} differs slightly from the one implemented in the code of
their experimental setting. In this paper we use the latter.}:
(1) a uniform distribution over $[1, 100]$ for each individual weight, and (2)
a normal distribution with mean $25$ and covariance
$\frac{25}{3}$.  We further produced two novel
{\em sparse} sets of weight vectors by deleting $80\%$ of the entries of the
vectors sampled in the uniform and normal settings uniformly at random
\stefano{Paolo, is this correct?}. All methods were evaluated on the very same
weight vectors.

In Figure~\ref{fig:} we plot, for each setting, the behavior of the utility
loss:
%
$$ \max_{\vx\in\calX_\text{feasible}} \left( u(\vx) - u(\vx^*) \right) $$
%
varying the number of collected user responses. Here $u(\cdot)$ is the
true unknown user utility, and $\vx^*$ is the solution recommended to
the user after the elicitation phase (see Algorithm~\ref{alg:setmargin}).

The thick line is the median
utility loss taken over all 20 users, while the shaded area represents the
standard deviation.

\stefano{plot average utility loss at the increase of dataset size}

\stefano{plot average runtime at the increase of dataset size}

\stefano{comment on usefulness of sparse weights}

\paragraph{Cognitive effort.} Contrarily to most other preference elicitation
methods, which generate a single candidate option per iteration, {\sc
SetMargin} constructs a whole {\em set} of options. We thus can not leverage
standard query selection strategies \stefano{which ones?}. 

The simplest solution is to query the user about all $k \choose 2$ pairs of
configurations in $\{\vx^i\}$. Since $k$ is a small constant, the resulting
number of queries does not grow large in practice.  An appealing alternative
involves using a modified sorting algorithm, such as merge-sort, to order the
set $\{\vx^i\}$ by asking only $O(n\log n)$ queries to the user. However, this
approach is very susceptible to noise: a single inconsistent user response may
affect all successive comparisons, leading to a cascading effect. While more
robust strategies may be conceived, empirically we found that the simpler
quadratic scheme tends to work reasonably well.

\andrea{rewrite as footnote}


\paragraph{Constructive dataset.} Next, we tested {\sc SetMargin} on a truly
constructive setting. We developed a constructive version of the PC dataset
used in~\cite{guo2010real}: instead of explicitly enumerating all possible PC
item, we definined the set of feasible configurations through MILP constraints.

A PC configurations is defined by eight attributes: computer type (laptop,
desktop, or tower), manufacturer (8 choices), CPU model (37), monitor size (8), RAM amount (10), storage (10)
size, and price.
%See Table~\ref{tab:pcdataset} for an overivew of the attributes.
The price attribute is defined as a linear combination of the other
attributes: this is a fair modeling choice, as often the price of a PC is
well approximated by sum of the price of its components plus an offset due to
branding.
%
Interactions between attributes are expressed as Horn clauses. An example
constraint might look like this: ``if the manufacturer is Apple, then the
CPU must be either a PowerPC G3 or a PowerPC G4''\footnote{Despite the components
included in the dataset, which are a bit outdated, the dataset itself is pretty
realistic.}, which can be encoded
into MILP form as
%
$ (1 - x_\text{Apple}) + x_\text{G3} + x_\text{G4} \ge 1 $.
%
Note that mutual exclusivity between all binary variables of the
one-hot encoding of an attribute ensures that only one of
$x_\text{G3}$ and $x_\text{G4}$ can be 1.  The dataset includes
constraints between the following attributes: manufacturer $\to$ type,
manufacturer $\to$ CPU, type $\to$ RAM amount, type $\to$ storage
size, type $\to$ monitor size, for 16 Horn constraints total. We
do not report the full list due to space limitations.

% \begin{table}
%     \centering
%     \begin{tabular}{ccc}
%         {\bf Attribute} & {\bf Type} & {\bf Values} \\
%         \hline \hline
%         Type & discrete & 3 \\
%         Manufacturer & discrete & 8 \\
%         CPU model & discrete & 37 \\
%         RAM amount & discrete & 10 \\
%         HD size & discrete & 10 \\
%         Monitor size & discrete & 8 \\
%         Price & continuous & --
%     \end{tabular}
%     \caption{\label{tab:pcdataset} Statistics for the PC dataset.}
% \end{table}

\stefano{Add figures and comments.}

\section{Conclusion}
\label{sec:conclusions}

This paper presented a maxmargin approach to generating a set of diverse examples.
Our approach, that can be seen as an extension of maxmargin learning to sets, is effective in the generation of a diverse set of items that can be used to ask informative queries to the user.
The main advantages of our elicitation method are 1) its aptitude for eliciting preferences and providing recommendations in large configuration problems  2) robustness with respect to erroneous preference input, and 3) its ability to support sparse utility functions.
In a number of experiments we showed how our method compare with state-of-the-art approaches.

\paolo{any idea about possible future works?}
% FUTURE WORKS

%\section*{Acknowledgments}
%WRITEME

\bibliographystyle{named}
\bibliography{ijcai16}

\onecolumn

\begin{figure}[b]
    \centering
    {\footnotesize
    \begin{tabular}{cccc}
        \hline
        {\sc synthetic 3 loss} & {\sc synthetic 4 loss} & {\sc synthetic 5 loss} & {\sc synthetic 5 time}
        \\
        \hline \hline
        \multicolumn{4}{c}{{\sc Uniform}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Uniform Sparse}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Normal}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Normal Sparse}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time}
        \\
        \hline
    \end{tabular}
    }
    \caption{\label{fig:comparison} {\sc SetMargin} vs Guo vs Viappiani.}
\end{figure}

\begin{figure}[b]
    \centering
    {\footnotesize
    \begin{tabular}{cccc}
        \hline
        \multicolumn{2}{c}{{\sc per query loss}} &
        \multicolumn{2}{c}{{\sc per iter. loss}}
        \\
        {\sc synthetic 4} & {\sc synthetic 6} & {\sc synthetic 4} & {\sc synthetic 6}
        \\
        \hline \hline
        \multicolumn{4}{c}{{\sc Uniform}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Uniform Sparse}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Normal}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Normal Sparse}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/loss}
        \\
        \hline
    \end{tabular}
    \caption{\label{fig:selfcomparison} Self-comparison experiment. Only
    losses, per-query and per-iteration. Runtime described in the text. Each
    row is a user sampling mode. Three curves per plot: $k=2$ vs $k=3$ vs
    $k=4$.}
    }
\end{figure}

\begin{figure}[b]
    \centering
    {\footnotesize
    \begin{tabular}{cccc}
        \hline
        \multicolumn{4}{c}{{\sc uniform sparse}}
        \\
        \multicolumn{2}{c}{{\sc loss/time per iteration}} &
        \multicolumn{2}{c}{{\sc loss/time per query}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc normal sparse}}
        \\
        \multicolumn{2}{c}{{\sc loss/time per iteration}} &
        \multicolumn{2}{c}{{\sc loss/time per query}}
        \\
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time} &
        \includegraphics[width=10em]{figures/loss} &
        \includegraphics[width=10em]{figures/time}
        \\
        \hline
    \end{tabular}
    }
    \caption{Results for the PC dataset.}
\end{figure}

\twocolumn

\end{document}
