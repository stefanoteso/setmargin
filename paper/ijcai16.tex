%%%% ijcai16.tex

\typeout{Constructive Preference Elicitation by Setwise Max-margin Learning}

\documentclass{article}
\usepackage{ijcai16}
\usepackage{times}
%\usepackage{latexsym}
\usepackage{graphicx}

\RequirePackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}

% ---------------------------------------------------------------------------

\algrenewcommand{\algorithmicrequire}{\textbf{Input:}}
\algrenewcommand{\algorithmicensure}{\textbf{Output:}}

\renewcommand\[{\begin{equation}}
\renewcommand\]{\end{equation}}

% Bold math symbols
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\bbB}{\mathbb{B}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbD}{\mathbb{D}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbG}{\mathbb{G}}
\newcommand{\bbH}{\mathbb{H}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbJ}{\mathbb{J}}
\newcommand{\bbK}{\mathbb{K}}
\newcommand{\bbL}{\mathbb{L}}
\newcommand{\bbM}{\mathbb{M}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbO}{\mathbb{O}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\bbT}{\mathbb{T}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbV}{\mathbb{V}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbY}{\mathbb{Y}}
\newcommand{\bbZ}{\mathbb{Z}}

% Calligraphic math symbols
\newcommand{\calvar}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\calA}{\calvar{A}}
\newcommand{\calB}{\calvar{B}}
\newcommand{\calC}{\calvar{C}}
\newcommand{\calD}{\calvar{D}}
\newcommand{\calE}{\calvar{E}}
\newcommand{\calF}{\calvar{F}}
\newcommand{\calG}{\calvar{G}}
\newcommand{\calH}{\calvar{H}}
\newcommand{\calI}{\calvar{I}}
\newcommand{\calJ}{\calvar{J}}
\newcommand{\calK}{\calvar{K}}
\newcommand{\calL}{\calvar{L}}
\newcommand{\calM}{\calvar{M}}
\newcommand{\calN}{\calvar{N}}
\newcommand{\calO}{\calvar{O}}
\newcommand{\calP}{\calvar{P}}
\newcommand{\calQ}{\calvar{Q}}
\newcommand{\calR}{\calvar{R}}
\newcommand{\calS}{\calvar{S}}
\newcommand{\calT}{\calvar{T}}
\newcommand{\calU}{\calvar{U}}
\newcommand{\calV}{\calvar{V}}
\newcommand{\calW}{\calvar{W}}
\newcommand{\calX}{\calvar{X}}
\newcommand{\calY}{\calvar{Y}}
\newcommand{\calZ}{\calvar{Z}}

% Vectors
\newcommand{\vecvar}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\va}{\vecvar{a}}
\newcommand{\vb}{\vecvar{b}}
\newcommand{\vc}{\vecvar{c}}
\newcommand{\vd}{\vecvar{d}}
\newcommand{\ve}{\vecvar{e}}
\newcommand{\vf}{\vecvar{f}}
\newcommand{\vg}{\vecvar{g}}
\newcommand{\vh}{\vecvar{h}}
\newcommand{\vi}{\vecvar{i}}
\newcommand{\vj}{\vecvar{j}}
\newcommand{\vk}{\vecvar{k}}
\newcommand{\vl}{\vecvar{l}}
\newcommand{\vm}{\vecvar{m}}
\newcommand{\vn}{\vecvar{n}}
\newcommand{\vo}{\vecvar{o}}
\newcommand{\vp}{\vecvar{p}}
\newcommand{\vq}{\vecvar{q}}
\newcommand{\vr}{\vecvar{r}}
\newcommand{\vs}{\vecvar{s}}
\newcommand{\vt}{\vecvar{t}}
\newcommand{\vu}{\vecvar{u}}
\newcommand{\vv}{\vecvar{v}}
\newcommand{\vw}{\vecvar{w}}
\newcommand{\vx}{\vecvar{x}}
\newcommand{\vy}{\vecvar{y}}
\newcommand{\vz}{\vecvar{z}}
\newcommand{\valpha}{\vecvar{\alpha}}
\newcommand{\veps}{\vecvar{\varepsilon}}
\newcommand{\vphi}{\vecvar{\varphi}}
\newcommand{\vpsi}{\vecvar{\psi}}
\newcommand{\vtheta}{\vecvar{\theta}}

% Operators
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

% Debugging

\usepackage{color}
\newcommand{\andrea}[1]{{\bf \textcolor{blue}{{\fbox{Andrea:} #1}}}}
\newcommand{\stefano}[1]{{\bf \textcolor{green}{{\fbox{Stefano:} #1}}}}
\newcommand{\paolo}[1]{{\bf \textcolor{red}{{\fbox{Paolo:} #1}}}}

% ---------------------------------------------------------------------------

\title{Constructive Preference Elicitation by Setwise Max-margin Learning}
\author{ST and AP and PV}

\begin{document}

\maketitle

\begin{abstract}
WRITEME
\end{abstract}

\section{Introduction}

WRITEME

- importance of recommendation systems and preference elicitation

- existing approaches and their limitations

% constructive preference elicitation
In this paper we take a {\em constructive} view on preference
elicitation, enlarging its scope from the selection of items among a
set of candidates to the synthesis of entirely novel
instances. Instances are represented as combinations of basic elements
(e.g. the components of a laptop) subject to a set of constraints
(e.g. the laptop model determines the set of available CPUs). A
utility function is learned over the feature representation of an
instance, as customary in many preference elicitation approaches. The
recommendation is then made by solving a constrained optimization
problem in the space of feasible instances, guided by the learned
utility. \andrea{other constructive preference elicitation approaches?}

% setwise max-margin formulation to deal with uncertainty in user utility
Learning a user utility function requires setting a preference
elicitation strategy and dealing with uncertain and possibly
inconsistent user feedback. Bayesian preference elicitation approaches
deal with both problems by building a probability distribution on
candidate functions and asking queries maximizing informativeness
measures such as expected value of information (EVOI)~\cite{}. These
approaches are however computationally expensive and cannot scale to
fully constructive scenarios, as shown in our experimental results.
We take a space decomposition perspective and jointly learn a set of
weight vectors, each representing a candidate utility function,
maximizing diversity between the vectors and consistency with the
available feedback. These two conflicting objectives tend to generate
equally plausible alternative hypotheses for the unknown
utility. Preference elicitation works by combining weight vector
learning with instance generation, so that each iteration of the
algorithm produces two outcomes: a set of weight vectors and a set of
instances, each maximizing its score according to one of the weight
vectors. 


- experimental results

- paper structure


\section{Related Work}

WRITEME

\section{Setwise Max-margin Learning}

\stefano{Paolo, Andrea, feel free to improve the text and especially the
citations as you see fit.}

\paragraph{Notation.} We use boldface letters $\vx$ to indicate vectors,
uppercase letters $X$ for matrices, and calligraphic capital letters $\calX$
for sets. We frequently abbreviate the set $\{ x^i \}_{i=1}^n$ as $\{ x^i \}$
whenever the range of the index $i$ is clear from the context, and use $[n]$ as
a shorthand for the set $\{1, \ldots, n\}$. We write $\|\vx\|_1 := \sum_z |x_z|$
to indicate the $\ell_1$ vector norm, and $\langle \cdot, \cdot \rangle$ to
denote the usual dot product.

\paragraph{Setting.} We assume to have a multi-attribute feature space $\calX$
of configurations $\vx = (x_1, \ldots, x_n)$ over $n$ features. For the time
being we will focus on binary features only, i.e. $x_z\in\{0,1\}$ for all
$z\in[n]$, to keep matters simple. This is a common choice for preference
elicitation methods~\cite{guo2010real,viappiani2010optimal}; discrete features
can be handled for instance by means of a simple one-hot encoding. Support for
linearly dependent continuous features will be discussed later on.

We further assume that the set of {\em feasible} configurations, denoted by
$\calX_\text{feasible}$, is expressed as
a conjunction of linear constraints. This is not a severe restriction:
arbitrary propositional constraints can be trivially encoded in this setting,
e.g. under the canonical mapping of $True$ to $1$ and $False$ to $0$, the
Boolean disjunction of two binary variables $x_1 \lor x_2$ can be rewritten as
$x_1 + x_2 \ge 1$.

In adherence to previous work~\cite{guo2010real,viappiani2010optimal}, we model users by means
of linear utility functions: the user's preferences are represented by a weight
vector $\vw\in\bbR^n$, and the utility of a configuration $\vx$ is given by
$\langle \vw, \vx \rangle = \sum_{z=1}^n w_z x_z$. In the remainder of the paper we
require all weights to be {\em non-negative} and {\em bounded}: the per-attribute
weights $w_z$ must lie in a (constant but otherwise arbitrary) interval
$[w^\bot_z, w^\top_z]$, with $w^\bot_z \ge 0$. Both requirements are quite
natural, and enable the translation of our core optimization problem into a
mixed-integer linear problem (as done in Section~\ref{sec:formulation}).

During learning, the actual weight vector $\vw$ is {\em unknown} to the
learning system, and must be estimated from pairwise choices elicited from the
user.  We consider three possible outcomes for a pairwise comparison between
two configurations $\vx$ and $\vx'$: either $\vx$ is preferred to $\vx'$ (written
$\vx \succ \vx'$), $\vx'$ is preferred to $\vx$ ($\vx \prec \vx'$), or there is
no clear preference between the two items ($\vx \approx \vx'$). We write
$\calD$ to denote the full set of answers elicited from the user. Queries are
typically selected so as to maximize some measure of informativeness of the
resulting responses.  Details on our actual query selection strategy will be
provided in Section~\ref{sec:formulation}.

\subsection{Problem Formulation}
\label{sec:formulation}

\paragraph{Non-linear Formulation.} We now introduce an initial formulation of
the optimization problem, that we do {\em not} aim at solving directly.

In the set-margin approach, the goal is twofold. First, for any given set size
$k\geq 1$, we want to find a {\em set} of $k$ weight vectors $\vw^{1}, \ldots,
\vw^{k}$, chosen so that all user-provided preferences are satisfied by the
largest possible margin (i.e. all weight vector are consistent with respect to
the user responses $\calD$, modulo inconsistencies) and so that they are
maximally diverse.  Second, we want to construct a {\em set} of $k$
configurations $\vx^{1}, \ldots, \vx^{k}$, so that each configuration $\vx^{i}$
is the ``best'' possible option when evaluated according to the corresponding
$\vw^{i}$, and consequently maximally diverse as well. These options will be
later employed to formulate the user queries.

The first goal achieved by translating all pairwise preferences $\calD$ into
ranking constraints: preferences of the form $\vy^h_+ \succ \vy^h_-$ become
linear inequalities of the form $\langle \vw^i, \vy^h_+ - \vy^h_- \rangle \geq
M$, where $M$ is the {\em margin} variable (which we aim at maximizing) and $h$
ranges over the responses.  Non-separable datasets, which occur in practice due
to user inconsistency, are handled by introducing slack variables (whose sum we
aim at minimizing). When augmented with the slacks, the above inequalities take
the form:
%
$$ \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge M - \varepsilon^{i}_h $$
%
where $\varepsilon^{i}_h$ is the penalty incurred by weight vector $\vw^{i}$
for violating the ranking of example $h$. Indifference preferences, i.e.
$\vy^h_1 \approx \vy^h_2$, are translated as $|\langle \vw^i, \vy^h_1 - \vy^h_2 \rangle| < \varepsilon^i_h$:
the slack increases with the difference between the estimated utility of the
two options.

Ideally, the second goal would be implemented as:
%
$$ \vx^{i} = \argmax_{\vx \in \calX_\text{feasible}} \langle \vw^{i}, \vx^{i} \rangle $$
%
However this formulation is highly impractical. We therefore only require 
each option $\vx^{i}$ to be the best {\em among} the configurations
$\{ \vx^i \}$. This can be accomplished by imposing
constraints of the form $\langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \geq M$
for all $i,j\in[k]$, $i \ne j$.
This however does not guarantee that the produced $\{ \vx^{i} \}$ have a high
{\em absolute} utility. We therefore favor high-quality configurations by
introducing an additional term $\sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle$
in the objective function.

A straightforward encoding of the above desiderata leads to the following {\em
non-linear} optimization problem over the variables $M$, $\{ \vw^i \}$, $\{ \vx^i \}$:
%
{\footnotesize
\begin{align}
    \max
        & \;\; M - \alpha \sum_{i=1}^k \| \veps^{i} \|_1 - \beta \sum_{i=1}^k \| \vw^{i} \|_1 + \gamma \sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle
        \nonumber
    \\
    \text{s.t.}
        & \;\; \forall \; i \in [k], \forall \; h \in [n] \nonumber
    \\
        & \;\; \qquad \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge M - \varepsilon^{i}_h \label{eq:wyconstr}
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \;.\; \langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \ge M \label{eq:wxconstr}
    \\
        & \;\; \forall \; i \in [k] \;.\; \vw^\bot \le \vw^{i} \le \vw^\top \label{eq:wbounds}
    \\
        & \;\; \forall \; i \in [k] \;.\; \vx^{i} \in \calX_{\text{feasible}} \label{eq:xbounds}
    \\
        & \;\; \forall \; i \in [k] \;.\; \veps^{i} \ge 0 \nonumber
    \\
        & \;\; M \ge 0 \nonumber
\end{align}
}
%
Let us illustrate the above piece by piece. The objective is composed of four
parts: we maximize the shared margin $M$ (first part) and minimize the total
sum of the ranking errors $\veps^i$ incurred by each weight vector $\vw^{i}$
(second part), while at the same time regularizing the magnitude of the
weights (third part) and quality of the configurations $\{ \vx^{i} \}$ (last
part). The non-negative hyperparameters $\alpha,\beta,\gamma$ control the
influence of the various components.

The third part of the objective does require a more in depth explanation. In
many scenarios the user will have strong preferences about some attributes, but
will be indifferent to most of them~\cite{}. The $\ell_1$ penalty is frequently
used to improve the sparsity of learned models~\cite{}, with consequent gains
in generalization ability and efficiency, as confirmed by our empirical
findings (see Section~\ref{sec:experiments}). \stefano{add refs}

The two core constraints as Equations~\ref{eq:wyconstr} and \ref{eq:wxconstr},
which are taken directly from the discussion above. The former enforces the
correct ranking of the observed user preferences, while the latter ensures that
the generated configurations are ranked correctly with respect to the
corresponding weight vectors. Equations \ref{eq:wbounds} and \ref{eq:xbounds}
ensure that the weights and configurations are in fact feasible, while the
remaining two guarantee the non-negativity of the slack and margin variables.
Since we require $\vw^\bot \ge 0$, Eq.~\ref{eq:wbounds} also enforces the
weights to be non-negative.

Note that we are choosing the options $\{ \vx^i \}$ and the weight vectors $\{
\vw^i \}$ {\em simultaneously}. Since we maximize the margin $M$, the optimizer
will prefer a set of outcomes $\{ \vx^{i} \}$ that partition the weight space
roughly equally, and corresponding utility functions such that each $\vw^{i}$
lies (intuitively) close to the centre of each subregion. See
Figure~\ref{fig:setmargin} for a depiction of this intuition.

\stefano{for $k=1$, setting $\alpha < 1$  renders the problem unbounded, as
Eq.~\ref{eq:wxconstr} vanishes.}

\begin{figure}[t]
    \begin{center}
        \includegraphics[width=16em]{figures/setmargin}
    \end{center}
    \caption{\label{fig:setmargin} Intuition.}
\end{figure}

\paragraph{MILP Formulation.} This initial formulation is problematic, as
Eq~\ref{eq:wxconstr} involves quadratic terms. Here we show how to reformulate
the problem as a mixed integer linear program (MILP). Our goal is to replace
Eq~\ref{eq:wxconstr} with a set of linear constraints through a suitable
variable transformation.

In order to do so, we introduce a set of fresh variables $p^{i,j}_z$ for every
$i,j\in[k]$ and $z\in[n]$. Assuming for the time being that the new variables
do satisfy the equation $p^{i,j}_z = w^i_z x^i_z$, we rewrite the fourth
component of the objective function in terms of the new variables as:
%
$$ \gamma \sum_{i=1}^k \sum_{z=1}^n p^{i,i}_z $$
%
and, similarly, Eq~\ref{eq:wxconstr} as:
%
\[ \forall \; i, j \in [k], i \neq j \;.\; \sum_{z=1}^n p^{i,i}_z - p^{i,j}_z \ge M \label{eq:pxconstr} \]
%
The fact that $p^{i,j}_z = w^{i}_z x^{i}_z$ is achieved by
setting the following additional constraints. We distinguish between two cases:
(i) $p^{i,i}_z$, and (ii) $p^{i,j}_z$ for $i \ne j$.  Recall that we are
maximizing the margin $M$. Now, due to Eq~\ref{eq:pxconstr}, the optimizer will
try to keep $p^{i,i}_z$ as large as possible and $p^{i,j}_z$ as small as
possible.

(Case i) We add an explicit upper bound:
%
$$ p^{i,i}_z \le \min \{ w_\text{max} x^{i}_z, w^{i}_z \} $$
%
where $w_\text{max}$ is a sufficiently large constant.
On one hand, if $x^i_z = 0$ the product $w^i_z x^i_z$ evaluates to $0$, and so does
the upper bound $w_\text{max} x^{i}_z = 0$. On the other hand, if $x^i_z=1$
then the product $w^i_z x^i_z$ amounts to $w^i_z$, while the upper
bound reduces to $\min \{ w_\text{max}, w^{i}_z \}$. By taking a sufficiently
large constant $w_\text{max}$ (e.g. $w_\text{max} := \max_z w^\top_z$) the
upper bound simplifies to $w^i_z$. Since $p^{i,i}_z$ is being maximized, in
both cases it will attain the upper bound, and thus satisfy $p^{i,j}_z = w^i_z x^i_z$.

(Case ii) We add an explicit lower bound:
%
$$ p^{i,j}_z \ge \max \{ 0, w^{i}_z - w_\text{max}(1 - x^{j}_z) \} $$
%
If $x^i_z = 1$ the lower bound simplifies to $\max \{ 0, w^{i}_z \} = w^{i}_z$,
due to the non-negativity of $w^i_z$. Otherwise, if $x^i_z = 0$
then the lower bound becomes $\max \{ 0, w^{i}_z - w_\text{max} \}$, where
the second term is at most $0$. Since $p^{i,j}_z$ is being minimized, in both
cases it will attain the lower bound, and thus satisfy $p^{i,j}_z = w^i_z
x^i_z$\footnote{Since $M$ is upper-bounded by Eq.~\ref{eq:wyconstr}, in some
cases the $p^{i,j}_z$ variables do not attain the lower bound. As a
consequence, the MILP reformulation of Eq.~\ref{eq:wxconstr} is marginally
inexact. Despite this issue, the MILP formulation acceptably in practice.}.

Substituting the above MILP constraints into the original non-linear
formulation, we obtain the following mixed-integer linear problem:
%
{\footnotesize
\begin{align}
    \max
        & \;\; M - \alpha \sum_{i=1}^k \| \veps^{i} \|_1 - \beta \sum_{i=1}^k \| \vw^{i} \|_1 + \gamma \sum_{i=1}^k \sum_{z=1}^n p^{i,i}_z
        \nonumber
    \\
    \text{s.t.}
        & \;\; \forall \; i \in [k], \forall \; h \in [n] \nonumber
    \\
        & \;\; \qquad \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge M - \varepsilon^{i}_h \nonumber
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \;.\; \sum_{z=1}^n p^{i,i}_z - p^{i,j}_z \ge M
    \\
        & \;\; \forall \; i \in [k], \forall \; z \in [n] \nonumber
    \\
        & \;\; \qquad p^{i,i}_z \le \min \{ w_\text{max} x^{i}_z, w^{i}_z \}
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \nonumber
    \\
        & \;\; \qquad p^{i,j}_z \ge \max \{ 0, w^{i}_z - w_\text{max}(1 - x^{j}_z) \}
    \\
        & \;\; \forall \; i \in [k] \;.\; \vw^\bot \le \vw^{i} \le \vw^\top \label{eq:wbounds2}
    \\
        & \;\; \forall \; i \in [k] \;.\; \vx^{i} \in \calX_{\text{feasible}} \nonumber
    \\
        & \;\; \forall \; i \in [k] \;.\; \veps^{i}_h \ge 0 \nonumber
    \\
        & \;\; M \ge 0 \nonumber
\end{align}
}
%
which can be solved by any suitable MILP solver.

\paragraph{Set-wise max-margin.} The full {\sc SetMargin} algorithm follows the
usual preference elicitation loop. Starting from an initially empty set of user
responses $\calD$, it repeatedly solves the MILP problem above using the set
$\calD$ to enforce ranking constraints on the weight vectors $\{\vw^i\}$. The
generated configurations $\{\vx^i\}$, which are chosen to be as good as
possible with respect to the estimated user preferences, and as diverse as
possible, are then employed to formulate a set of user queries. The new replies
are added to $\calD$ and the whole procedure is repeated. The algorithm
terminates after a fixed number of iterations, or once another suitable
condition is met. The procedure is sketched in Algorithm~\ref{alg:setmargin}.

\begin{algorithm}
{\footnotesize
\begin{algorithmic}[1]
    \Procedure{SetMargin}{$k, \alpha, \beta, \gamma, T$}
        \State $\calD \gets \emptyset$
        \For{$t = 1, \ldots, T$}
            \State \{$\vw^{i}, \vx^{i}\}_{i=1}^k \gets \text{{\sc Solve}}(\calD, k, \alpha, \beta, \gamma)$
            \For{$\vx^{i},\vx^{j} \in \{ \vx^{1}, \ldots, \vx^{k} \} \; \text{{\bf s.t.}} \; i < j$}
                \State $\calD \gets \calD \cup \text{{\sc QueryUser}}(\vx^{i},\vx^{j})$
            \EndFor
        \EndFor
        \State $\vw^*, \vx^* \gets \text{{\sc Solve}}(\calD, 1, \alpha, \beta, \gamma)$
        \State ${\bf return}\; \vw^*, \vx^*$
    \EndProcedure
\end{algorithmic}
}
\caption{\label{alg:setmargin} The {\sc SetMargin} algorithm. Here $k$ is the
set size, $\alpha,\beta,\gamma$ are the hyperparameters, and $T$ is the maximum
number of iterations. The values of $\calX_\text{feasible}$, $\vw^\top$ and
$\vw^\bot$ are left implicit.}
\end{algorithm}

\paragraph{Query selection.} Contrarily to most other preference elicitation
methods, which generate a single candidate option per iteration, {\sc
SetMargin} constructs a whole {\em set} of options. We thus can not leverage
standard query selection strategies \stefano{which ones?}.

The simplest solution is to query the user about all $k \choose 2$ pairs of
configurations in $\{\vx^i\}$. Since $k$ is a small constant, the resulting
number of queries does not grow large in practice.  An appealing alternative
involves using a modified sorting algorithm, such as merge-sort, to order the
set $\{\vx^i\}$ by asking only $O(n\log n)$ queries to the user. However, this
approach is very susceptible to noise: a single inconsistent user response may
affect all successive comparisons, leading to a cascading effect. While more
robust strategies may be conceived, empirically we found that the simpler
quadratic scheme tends to work reasonably well.

\paragraph{Linearly dependent real attributes.} In many domains of interest,
items are composed of both Boolean and real-valued attributes, where the latter
depend linearly  on the former. This is for instance the case for the price,
weight and power consumption of a laptop model, which depend linearly on the
choice of components.
%
In this setting, item configurations are composed of two parts: $\vx =
(\vx_B;\vx_R)$, where $\vx_B$ is Boolean and $\vx_R$ is real-valued, and the
relation between the two is entirely described by an appropriately sized
non-negative cost matrix $C$, such that $\vx_R = C \vx_B$. It is
straightforward to extend the MILP formulation to this setting, as follows.

First, we rewrite the weight vector as $\vw = (\vw_B;\vw_R)$. The utility
becomes:
%
$$ \langle \vw, \vx \rangle = \langle \vw_B, \vx_B \rangle + \langle \vw_R, C \vx_B \rangle = \langle \vw_B + C^\top \vw_B, \vx_B \rangle $$
%
The generalized problem is obtained by substituting $\vw^i$ with $\vv^i := \vw_B^i + C^\top \vv_B^i$ and $p^{i,j}_z$
with $q^{i,j}_z := (\vw^i_B + C^\top \vw^i_R)_z x^j_z$ in the MILP problem.
All constraints remain the same, except Eq.~\ref{eq:wbounds2}, which must be
rewritten in terms of $\vv^i$:
%
$$ \forall \; i \in [k] \;.\; (\vw_B^\bot + C^\bot \vw_R) \le \vv^i \le (\vw_B^\top + C^\top \vw_R^\top)$$
%
As can be seen, non-negativity of $C$ is required for the weights $\{\vv^i\}$
to be non-negative.

\section{Experiments}
\label{sec:experiments}

We implemented the {\sc SetMargin} algorithm using Python, leveraging Gurobi
6.5.0 for solving the core MILP problem. Both the {\sc SetMargin} source code
and the full experimental setup are available at \stefano{add URL}.

We compare {\sc SetMargin} against two strong Bayesian baselines:
\cite{guo2010real} and \cite{viappiani2010optimal}.
\stefano{Paolo, could you describe the baselines?}

We adopt the {\em indifference-augmented} Bradley-Torr user response model
introduced in~\cite{guo2010real}. When queried about a pair of configurations,
the user replies with the true utility of the two items. According to the
classical Bradley-Torr model, which does not attempt to model {\em indifference},
the proabability that a user $\vw$ will prefer configuration $\vx^i$ over
the alternative $\vx^j$, barring indifference, amounts to:
%
$$ (1 + \exp(-\alpha \langle\vw,\vx^i - \vx^j\rangle))^{-1} $$
%
In other words, the probability grows with the difference between the utilities
of the two items. Support for indifference has been introduced
in~\cite{guo2010real} by postulating that the probability of the user being
indifferent about the two configurations $\vx^i, \vx^j$ depends on how close
the two utilities are, as in:
%
$$ \exp(\beta |\langle\vw,\vx^i - \vx^j\rangle|) $$
%
The parameters $\alpha$ and $\beta$ were set as in~\cite{guo2010real}. Please
see the latter for more details
\stefano{The above does not satisfy me at all.}

In all experiments we use an internal 5-fold cross-validation procedure to
update the hyperparameters $\alpha$, $\beta$, and $\gamma$ after every 5
iterations. The hyperparameters are chosen as to minimize the ranking loss over
the user responses collected so far. $\alpha$ is taken in $\{20, 10, 5, 1\}$,
while $\beta$ and $\gamma$ are taken in $\{10, 1, 0.1, 0.001\}$.
\stefano{explain that we can't turn off $\gamma$}

\paragraph{Synthetic Dataset.} Following the experimental protocol
in~\cite{guo2010real} and \cite{viappiani2010optimal}, in the first experiment
we evaluate the behavior of the proposed method in a challenging artificial
setting. We developed seven synthetic datasets: each dataset involves
$n=2,\ldots,7$ attributes, where each attribute takes one of $n$ possible
values. More explicitly, for $n=2$ the synthetic dataset is
$\calX_\text{feasible} = [2] \times [2]$, for $n=3$ to $\calX_\text{feasible} =
[3] \times [3] \times [3]$, and so on. The cardinality of
$\calX_\text{feasible}$ is $n^n$, and grows (super) exponentially with $n$. For
$n=3$, the dataset is comparable to the synthetic one used
in~\cite{guo2010real} and~\cite{viappiani2010optimal} (which have three domains
of size of 2, 2 and 5, respectively, for a total of 20 feasible
configurations), while for larger $n$ it grows much larger than those typically
used in the Bayesian preference elicitation literature, and as such represents
a good test bed for comparing the scalability of the various methods.
The feasible configuration space was encoded in {\sc SetMargin} through
appropriate MILP constraints, while the other methods required all datasets to
be explicitly grounded.

Users were simulated by drawing $20$ random utility vectors from each of four
different distributions. The first two mimic those used
in~\cite{guo2010real}\footnote{The normal distribution reported
in~\cite{guo2010real} differs slightly from the one implemented in the code of
their experimental setting. In this paper we use the latter.}:
(1) a uniform distribution over $[1, 100]$ for each individual weight, and (2)
a normal distribution with mean $25$ and covariance
$\frac{25}{3}$.  We further produced two novel
{\em sparse} sets of weight vectors by deleting $80\%$ of the entries of the
vectors sampled in the uniform and normal settings uniformly at random
\stefano{Paolo, is this correct?}. All methods were evaluated on the very same
weight vectors.

In Figure~\ref{fig:} we plot, for each setting, the behavior of the utility
loss:
%
$$ \left(\max_{\vx\in\calX_\text{feasible}} u(\vx)) - u(\vx^{i}) \right) $$
%
varying the number of collected user responses. The thick line is the median
utility loss taken over all 20 users, while the shaded area represents the
variance. 

\stefano{plot average utility loss at the increase of dataset size}

\stefano{plot average runtime at the increase of dataset size}

\stefano{comment on usefulness of sparse weights}

\paragraph{Constructive dataset.} Next, we tested {\sc SetMargin} on a truly
constructive setting. We developed a constructive version of the PC dataset
used in~\cite{guo2010real}: instead of explicitly enumerating all possible PC
item, we definined the set of feasible configurations through MILP constraints.

A PC configurations is defined by seven attributes: computer type (laptop,
desktop, or tower), manufacturer, CPU model, monitor size, RAM amount, storage
size, and price. See Table~\ref{tab:pcdataset} for an overivew of the
attributes. The price attribute is defined as a linear combination of the other
attributes: this is a fair modeling choice, as often the price of a PC is
well approximated by sum of the price of its components plus an offset due to
branding. Compared to the PC dataset in~\cite{guo2010real}, we combined the CPU
type and CPU frequency attributes into a single CPU attribute (e.g. ``PowerPC
G4 @733 MHz''), so to avoid multiplicative terms in the price function.
\stefano{too detailed/handwavy?}

Interactions between attributes are expressed as Horn clauses. An example
costraint might look like this: ``if the manufacturer is Apple, then the
CPU must be either a PowerPC G3 or a PowerPC G4'', which can be encoded
into MILP form as:
%
$$ (1 - x_\text{Apple}) + x_\text{G3} + x_\text{G4} \ge 1 $$
%
Note that mutual exclusivity between all binary variables corresponding to an
attribute ensures that only one of $x_\text{G3}$ and $x_\text{G4}$ can be 1.
The dataset includes constraints between the following attributes: manufacturer
$\to$ type, manufacturer $\to$ CPU, type $\to$ RAM amount, type $\to$ storage
size, type $\to$ monitor size. In total we encoded 16 Horn constraints, each
with one head and multiple options in the body. We do not report the full
list due to space limitations.

\begin{table}
    \centering
    \begin{tabular}{ccc}
        {\bf Attribute} & {\bf Type} & {\bf Values} \\
        \hline \hline
        Type & discrete & 3 \\
        Manufacturer & discrete & 8 \\
        CPU model & discrete & 37 \\
        RAM amount & discrete & 10 \\
        HD size & discrete & 10 \\
        Monitor size & discrete & 8 \\
        Price & continuous & --
    \end{tabular}
    \caption{\label{tab:pcdataset} Statistics for the PC dataset.}
\end{table}

- PC dataset without costs

- PC dataset with costs

\section{Conclusion}

WRITEME

\section*{Acknowledgments}

WRITEME

\bibliographystyle{named}
\bibliography{ijcai16}

\onecolumn

\begin{figure}[b]
    \centering
    \begin{tabular}{cccc}
        {\bf synthetic 3} & {\bf synthetic 4} & {\bf synthetic 5} & {\bf synthetic 6}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_cv1_loss}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_sparse_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_sparse_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_sparse_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_sparse_cv1_loss}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_cv1_loss}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_sparse_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_sparse_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_sparse_cv1_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_sparse_cv1_loss}
    \end{tabular}
    \caption{Results on the synthetic dataset, with crossvalidation at each step. Each row represents a different
    setting: uniform, uniform sparse, normal, normal sparse. Color indicates
    the set size $k$: orange means $k=2$, blue $k=3$, and violet $k=4$.}
\end{figure}

\begin{figure}[b]
    \centering
    \begin{tabular}{cccc}
        {\bf synthetic 3} & {\bf synthetic 4} & {\bf synthetic 5} & {\bf synthetic 6}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_cv5_loss}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_sparse_cv5_loss}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_cv5_loss}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_sparse_cv5_loss}
    \end{tabular}
    \caption{Results on the synthetic dataset, with crossvalidation every 5 steps. Each row represents a different
    setting: uniform, uniform sparse, normal, normal sparse. Color indicates
    the set size $k$: orange means $k=2$, blue $k=3$, and violet $k=4$.}
\end{figure}

\begin{figure}[b]
    \centering
    \begin{tabular}{cccc}
        {\bf synthetic 3} & {\bf synthetic 4} & {\bf synthetic 5} & {\bf synthetic 6}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_cv1_time}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_sparse_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_sparse_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_sparse_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_sparse_cv1_time}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_cv1_time}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_sparse_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_sparse_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_sparse_cv1_time} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_sparse_cv1_time}
    \end{tabular}
    \caption{Results on the synthetic dataset, with crossvalidation at each step. Each row represents a different
    setting: uniform, uniform sparse, normal, normal sparse. Color indicates
    the set size $k$: orange means $k=2$, blue $k=3$, and violet $k=4$.}
\end{figure}

\begin{figure}[b]
    \centering
    \begin{tabular}{cccc}
        {\bf synthetic 3} & {\bf synthetic 4} & {\bf synthetic 5} & {\bf synthetic 6}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_cv5_time}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_uniform_sparse_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_4_uniform_sparse_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_5_uniform_sparse_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_6_uniform_sparse_cv5_time}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_cv5_time}
        \\
        \includegraphics[width=12em]{figures/synthetic_3_normal_sparse_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_4_normal_sparse_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_5_normal_sparse_cv5_time} &
        \includegraphics[width=12em]{figures/synthetic_6_normal_sparse_cv5_time}
    \end{tabular}
    \caption{Results on the synthetic dataset, with crossvalidation every 5 steps. Each row represents a different
    setting: uniform, uniform sparse, normal, normal sparse. Color indicates
    the set size $k$: orange means $k=2$, blue $k=3$, and violet $k=4$.}
\end{figure}

\begin{figure}[b]
    \centering
    \begin{tabular}{cc}
        {\bf loss} & {\bf time}
        \\
        \multicolumn{2}{c}{{\bf uniform sparse (no costs)}}
        \\
        \includegraphics[width=12em]{figures/pc_no_costs_uniform_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/pc_no_costs_uniform_sparse_cv5_time}
        \\
        \multicolumn{2}{c}{{\bf normal sparse (no costs)}}
        \\
        \includegraphics[width=12em]{figures/pc_no_costs_normal_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/pc_no_costs_normal_sparse_cv5_time}
        \\
        \multicolumn{2}{c}{{\bf uniform sparse (with costs)}}
        \\
        \includegraphics[width=12em]{figures/pc_with_costs_uniform_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/pc_with_costs_uniform_sparse_cv5_time}
        \\
        \multicolumn{2}{c}{{\bf normal sparse (with costs)}}
        \\
        \includegraphics[width=12em]{figures/pc_with_costs_normal_sparse_cv5_loss} &
        \includegraphics[width=12em]{figures/pc_with_costs_normal_sparse_cv5_time}
    \end{tabular}
    \caption{Results for the PC dataset with and without costs.}
\end{figure}

\twocolumn

\end{document}
