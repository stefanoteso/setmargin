%%%% ijcai16.tex

\typeout{Constructive Preference Elicitation by Setwise Max-margin Learning}

\documentclass{article}
\usepackage{ijcai16}
\usepackage{times}
%\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{hyperref}

\RequirePackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}

% ---------------------------------------------------------------------------

\algrenewcommand{\algorithmicrequire}{\textbf{Input:}}
\algrenewcommand{\algorithmicensure}{\textbf{Output:}}

\renewcommand\[{\begin{equation}}
\renewcommand\]{\end{equation}}

% Bold math symbols
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\bbB}{\mathbb{B}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbD}{\mathbb{D}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbG}{\mathbb{G}}
\newcommand{\bbH}{\mathbb{H}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbJ}{\mathbb{J}}
\newcommand{\bbK}{\mathbb{K}}
\newcommand{\bbL}{\mathbb{L}}
\newcommand{\bbM}{\mathbb{M}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbO}{\mathbb{O}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\bbT}{\mathbb{T}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbV}{\mathbb{V}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbY}{\mathbb{Y}}
\newcommand{\bbZ}{\mathbb{Z}}

% Calligraphic math symbols
\newcommand{\calvar}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\calA}{\calvar{A}}
\newcommand{\calB}{\calvar{B}}
\newcommand{\calC}{\calvar{C}}
\newcommand{\calD}{\calvar{D}}
\newcommand{\calE}{\calvar{E}}
\newcommand{\calF}{\calvar{F}}
\newcommand{\calG}{\calvar{G}}
\newcommand{\calH}{\calvar{H}}
\newcommand{\calI}{\calvar{I}}
\newcommand{\calJ}{\calvar{J}}
\newcommand{\calK}{\calvar{K}}
\newcommand{\calL}{\calvar{L}}
\newcommand{\calM}{\calvar{M}}
\newcommand{\calN}{\calvar{N}}
\newcommand{\calO}{\calvar{O}}
\newcommand{\calP}{\calvar{P}}
\newcommand{\calQ}{\calvar{Q}}
\newcommand{\calR}{\calvar{R}}
\newcommand{\calS}{\calvar{S}}
\newcommand{\calT}{\calvar{T}}
\newcommand{\calU}{\calvar{U}}
\newcommand{\calV}{\calvar{V}}
\newcommand{\calW}{\calvar{W}}
\newcommand{\calX}{\calvar{X}}
\newcommand{\calY}{\calvar{Y}}
\newcommand{\calZ}{\calvar{Z}}

% Vectors
\newcommand{\vecvar}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\va}{\vecvar{a}}
\newcommand{\vb}{\vecvar{b}}
\newcommand{\vc}{\vecvar{c}}
\newcommand{\vd}{\vecvar{d}}
\newcommand{\ve}{\vecvar{e}}
\newcommand{\vf}{\vecvar{f}}
\newcommand{\vg}{\vecvar{g}}
\newcommand{\vh}{\vecvar{h}}
\newcommand{\vi}{\vecvar{i}}
\newcommand{\vj}{\vecvar{j}}
\newcommand{\vk}{\vecvar{k}}
\newcommand{\vl}{\vecvar{l}}
\newcommand{\vm}{\vecvar{m}}
\newcommand{\vn}{\vecvar{n}}
\newcommand{\vo}{\vecvar{o}}
\newcommand{\vp}{\vecvar{p}}
\newcommand{\vq}{\vecvar{q}}
\newcommand{\vr}{\vecvar{r}}
\newcommand{\vs}{\vecvar{s}}
\newcommand{\vt}{\vecvar{t}}
\newcommand{\vu}{\vecvar{u}}
\newcommand{\vv}{\vecvar{v}}
\newcommand{\vw}{\vecvar{w}}
\newcommand{\vx}{\vecvar{x}}
\newcommand{\vy}{\vecvar{y}}
\newcommand{\vz}{\vecvar{z}}
\newcommand{\valpha}{\vecvar{\alpha}}
\newcommand{\veps}{\vecvar{\varepsilon}}
\newcommand{\vphi}{\vecvar{\varphi}}
\newcommand{\vpsi}{\vecvar{\psi}}
\newcommand{\vtheta}{\vecvar{\theta}}

% Operators
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

% Debugging

\usepackage{color}
\newcommand{\andrea}[1]{{\bf \textcolor{blue}{{\fbox{Andrea:} #1}}}}
\newcommand{\stefano}[1]{{\bf \textcolor{green}{{\fbox{Stefano:} #1}}}}
\newcommand{\paolo}[1]{{\bf \textcolor{red}{{\fbox{Paolo:} #1}}}}

% ---------------------------------------------------------------------------

\title{Constructive Preference Elicitation by Setwise Max-margin Learning} %with?
\author{ID 2243}

\begin{document}

\maketitle

\begin{abstract}
  In this paper we propose an approach to preference elicitation that
  is suitable to large configuration spaces beyond the reach of
  existing state-of-the-art approaches. Our setwise max-margin method
  can be viewed as a generalization of max-margin learning to sets,
  and can produce a set of ``diverse'' items that can be used to ask
  informative queries to the user.  Moreover, the approach can
  encourage sparsity in the parameter space, in order to favor the
  assessment of utility towards combinations of weights that
  concentrate on just few features.  We present a mixed integer linear
  programming formulation and show how our approach compares
  favourably with Bayesian preference elicitation alternatives and
  easily scales to realistic datasets.
\end{abstract}

\section{Introduction}

Preferences \cite{Peintner2008} play an important role in artificial intelligence,
including fields spanning from recommender systems to automatic planning, 
from non monotonic reasoning to computational social choice and algorithmic decision theory.
The task of eliciting or learning preferences is therefore a crucial; typically only limited information about the user's preferences will be available and the cost of obtaining additional preference information will be high (from a cognitive and/or computational point of view).
The goal in preference elicitation is that of gaining enough information about the user's preferences %(typically represented by an utility function $u$, unknown to the system) 
in order to recommend a decision or a course of action.

The assessment of preferences have received considerable attention in the literature, with early works confined to the operation research and management literature mostly \cite{White1984,JacquetLagreze95}.
%In the past decade a number of researchers have considered elicitation of preferences from an artificial intelligence perspective%; within the machine learning field the term preference learning has been catching up.
%While preferences are often assessed using some ad-hoc rules \cite{},
Recently, in the last decade or so, a number of artificial intelligence researchers have proposed principled methods that elicit utility in an adaptive way \cite{chajewska2000,boutilier2002,Wang2003,boutilier2006,braziunas2007,guo2010real,viappiani2010optimal}; the aims is that of focusing on learning the ``important'' part of the utility, allowing to recommend good (or even optimal) decision with only a partial information about the utility function.

%braziunas-mmr:uai07,

%One option is to be Bayesian and to maintain a probability distribution over the possible realizations of the utility's parameters \cite{chajewska2000,boutilier2002,guo2010real,viappiani2010optimal}.
%Alternatively, when distribution information about the parameters is not available, one can reason about all feasible utility functions consistent with the currently known information about the user; from the user's response we are able to infer constraints on the parameters implicated in the utility model \cite{Wang2003,boutilier2006,braziunasmmr:uai07,viappiani2009}.
%This latter approach has also the advantage of avoiding the computationally demanding task of maintaining distribution information and performing Bayesian updates.

% constructive preference elicitation
While most works assume that items or decisions are available in a (possibly large)
dataset, in this paper we propose an adaptive elicitation framework that takes a {\em constructive} view on preference
elicitation, enlarging its scope from the selection of items among a
set of candidates to the synthesis of entirely novel instances. 
Instances are solutions to a given optimization problem; they are represented as combinations of basic elements
(e.g. the components of a laptop) subject to a set of constraints
(e.g. the laptop model determines the set of available CPUs). 
A utility function is learned over the feature representation of an
instance, as customary in many preference elicitation approaches. 
The recommendation is then made by solving a constrained optimization
 problem in the space of feasible instances, guided by the learned
utility. 

Preference elicitation in configuration problems has been previously tackled with regret-based elicitation \cite{boutilier2006,braziunas2007}, where minimax regret is used both
as a robust recommendation criterion and as a technique to drive elicitation in configuration problems.
The main limitation of the minimax regret approach is the lack of tolerance with respect to user inconsistency (the user might state that an item is preferred to another one, even though the latter has higher utility).

% setwise max-margin formulation to deal with uncertainty in user utility
Indeed, learning a user utility function requires setting a preference
elicitation strategy and dealing with uncertain and possibly
inconsistent user feedback. 
Bayesian preference elicitation approaches
deal with both problems by building a probability distribution on
candidate functions (endowed with a response or error model to be used for inference) and asking queries maximizing informativeness
measures such as expected value of information (EVOI)~\cite{chajewska2000,guo2010real,viappiani2010optimal}. 

These
approaches are however computationally expensive and can not scale to
fully constructive scenarios, as shown in our experimental results.
We take a space decomposition perspective and jointly learn a set of
weight vectors, each representing a candidate utility function,
maximizing diversity between the vectors and consistency with the
available feedback. These two conflicting objectives tend to generate
equally plausible alternative hypotheses for the unknown
utility. 
Our approach to preference elicitation works by combining weight vector
learning with instance generation, so that each iteration of the
algorithm produces two outcomes: a set of weight vectors and a set of
instances, each maximizing its score according to one of the weight
vectors. 

We evaluate the effectiveness of our approach by testing our elicitation method
in both synthetic and configuration problems, and comparing it to state-of-the-art
methods.

The paper is structured as follows: after discussing related works in next Section,
we present some background material in Section \ref{sec:background} 
and then proceed to our setwise maxmargin method in Section \ref{sec:formulation}; 
we discuss experimental results in Section \ref{sec:experiments}
and conclude with final remarks (Section \ref{sec:conclusions}).

%\section{Related Work}

%Preference elicitation for the customization of user interfaces \cite{gajos2005}.

%WRITEME

\section{Background}
\label{sec:background}
%\section{Preference Elicitation}

\paragraph{Notation.} We use boldface letters $\vx$ to indicate vectors,
uppercase letters $X$ for matrices, and calligraphic capital letters $\calX$
for sets. We frequently abbreviate the set $\{ x^i \}_{i=1}^n$ as $\{ x^i \}$
whenever the range of the index $i$ is clear from the context, and use $[n]$ as
a shorthand for the set $\{1, \ldots, n\}$. We write $\|\vx\|_1 := \sum_z |x_z|$
to indicate the $\ell_1$ vector norm, $\langle \cdot, \cdot \rangle$ to
denote the usual dot product, and $X'$ for matrix transposition.

\paragraph{Setting.} We assume to have a multi-attribute feature space
$\calX$ of configurations $\vx = (x_1, \ldots, x_m)$ over $m$
features. For the sake of simplicity we focus on binary features only,
i.e. $x_z\in\{0,1\}$ for all $z\in[m]$, assuming a one-hot encoding of
categorical features. This is a common choice for preference
elicitation methods~\cite{guo2010real,viappiani2010optimal}. Support
for linearly dependent continuous features will be discussed later on.

We further assume that the set of {\em feasible} configurations, denoted by
$\calX_\text{feasible}$, is expressed as
a conjunction of linear constraints. This allows to formulate both arithmetic
and logical constraints,
e.g. under the canonical mapping of $True$ to $1$ and $False$ to $0$, the
Boolean disjunction of two binary variables $x_1 \lor x_2$ can be rewritten as
$x_1 + x_2 \ge 1$.

Consistently with previous work~\cite{guo2010real,viappiani2010optimal}, 
we model users by means of utility functions of a given structure; the user's preferences are represented by a latent weight
vector $\vw\in\bbR^m$.
We assume linear utility functions; the utility of a configuration $\vx$ is given by
$\langle \vw, \vx \rangle = \sum_{z=1}^m w_z x_z$
(see \cite{keeney1976} for theoretical conditions justifying additive utility functions). 
In the remainder of the paper we
require all weights to be {\em non-negative} and {\em bounded}: the per-attribute
weights $w_z$ must lie in a (constant but otherwise arbitrary) interval
$[w^\bot_z, w^\top_z]$, with $w^\bot_z \ge 0$. 
Both requirements are quite natural\footnote{Utility values are defined on an
interval scale, therefore the assumption of non negativity is not restrictive as it is always possible to scale the values appropriately (see for instance \cite{Torra2007} and \cite{keeney1976}).}, and enable the translation of our core optimization problem into a
mixed-integer linear problem (as done in Section~\ref{sec:formulation}).

During learning, the actual weight vector $\vw$ is {\em unknown} to the
learning system, and must be estimated from pairwise choices elicited from the
user.
%\andrea{@PAOLO: qualche parola e reference per giustificare la scelta di pairwise queries?}  
Comparison queries are especially natural, asking a user if she prefers one option x to another y;
these comparisons can be extended to choice sets of more than two options \cite{viappiani2009,viappiani2010optimal}.
Comparison and choice queries are common in conjoint analysis \cite{louviere2000,toubia2004}.


We consider three possible outcomes for a pairwise comparison between
two configurations $\vx$ and $\vx'$: either $\vx$ is preferred to $\vx'$ (written
$\vx \succ \vx'$), $\vx'$ is preferred to $\vx$ ($\vx \prec \vx'$), or there is
no clear preference between the two items ($\vx \approx \vx'$). We write
$\calD$ to denote the set of preferences (answers to comparison queries) 
elicited from the user. Queries are typically selected so as to maximize 
some measure of informativeness of the
resulting responses.  Details on our actual query selection strategy will be
provided in Section~\ref{sec:formulation}.

\section{Setwise Max-margin Learning}
\label{sec:formulation}
\paragraph{Non-linear Formulation.} We first introduce the problem
formulation as a %mixed integer 
non-linear optimization problem, and
then show how to reduce it to a mixed integer linear program.% optimization one.

The goal of our setwise max-margin approach is twofold. First, for any
given set size $k\geq 1$, we want to find a {\em set} of $k$ weight
vectors $\vw^{1}, \ldots, \vw^{k}$, chosen so that all user-provided
preferences are satisfied by the largest possible margin (i.e. all
weight vectors are consistent with respect to the user responses
$\calD$, modulo inconsistencies) and so that they are maximally
diverse.  Second, we want to construct a {\em set} of $k$
configurations $\vx^{1}, \ldots, \vx^{k}$, so that each configuration
$\vx^{i}$ is the ``best'' possible option when evaluated according to
the corresponding $\vw^{i}$ and configurations are maximally diverse
among each other. These options will be later employed to formulate
the user queries.

The first goal is achieved by translating all pairwise preferences
$\calD$ into ranking constraints: preferences of the form
$\vy^h_+ \succ \vy^h_-$ become linear inequalities of the form
$\langle \vw^i, \vy^h_+ - \vy^h_- \rangle \geq \mu$, where $\mu$ is the
{\em margin} variable (which we aim at maximizing) and $h$ ranges over
the responses.  Non-separable datasets, which occur in practice due to
occasional inconsistencies in user feedback, are handled by
introducing slack variables (whose sum we aim at minimizing). When
augmented with the slacks, the above inequalities take the form:
\begin{align*}
\langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge \mu - \varepsilon^{i}_h 
\end{align*}
where $\varepsilon^{i}_h$ is the penalty incurred by weight vector $\vw^{i}$
for violating the margin separation of pair $h$. Indifference preferences, i.e.
$\vy^h_1 \approx \vy^h_2$, are translated as $|\langle \vw^i, \vy^h_1 - \vy^h_2 \rangle| < \varepsilon^i_h$;
the slack increases with the difference between the estimated utility of the
two options.

The second goal requires to jointly maximize the utility of each
$\vx^{i}$ according to its corresponding weight vector $\vw^i$ and its
scoring difference with respect to the other configurations $\vx^j$ in
the set. We achieve this by maximizing the sum of utilities
$\sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle$ and adding ranking
constraints of the form
$\langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \geq \mu$ for all
$i,j\in[k]$, $i \ne j$.


% Ideally, the second goal would be implemented as:
% %
% $$ \vx^{i} = \argmax_{\vx \in \calX_\text{feasible}} \langle \vw^{i}, \vx^{i} \rangle $$
% %
% However this formulation is highly impractical. We therefore only require 
% each option $\vx^{i}$ to be the best {\em among} the configurations
% $\{ \vx^i \}$. This can be accomplished by imposing
% constraints of the form $\langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \geq \mu$
% for all $i,j\in[k]$, $i \ne j$.
% This however does not guarantee that the produced $\{ \vx^{i} \}$ have a high
% {\em absolute} utility. We therefore favor high-quality configurations by
% introducing an additional term $\sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle$
% in the objective function.

A straightforward encoding of the above desiderata leads to the
following mixed integer {\em non-linear} optimization problem over the
variables $\mu \in \bbR$, $\{ \vw^i \in \bbR^m \}$, $\{ \vx^i \in \{0,1\}^m \}$:
%
{\footnotesize
\begin{align}
    \max
        & \;\; \mu - \alpha \sum_{i=1}^k \| \veps^{i} \|_1 - \beta \sum_{i=1}^k \| \vw^{i} \|_1 + \gamma \sum_{i=1}^k \langle \vw^{i}, \vx^{i} \rangle
        \nonumber
    \\
    \text{s.t.}
        & \;\; \forall \; i \in [k], \forall \; h \in [n] \nonumber
    \\
        & \;\; \qquad \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge \mu - \varepsilon^{i}_h \label{eq:wyconstr}
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \quad \langle \vw^{i}, \vx^{i} - \vx^{j} \rangle \ge \mu \label{eq:wxconstr}
    \\
        & \;\; \forall \; i \in [k] \quad \vw^\bot \le \vw^{i} \le \vw^\top \label{eq:wbounds}
    \\
        & \;\; \forall \; i \in [k] \quad \vx^{i} \in \calX_{\text{feasible}} \label{eq:xbounds}
    \\
        & \;\; \forall \; i \in [k] \quad \veps^{i} \ge 0 \nonumber
    \\
        & \;\; \mu \ge 0 \nonumber
\end{align}
}
%
Let us illustrate the above piece by piece. The objective is composed of four
parts: we maximize the shared margin $\mu$ (first part) and minimize the total
sum of the ranking errors $\veps^i$ incurred by each weight vector $\vw^{i}$
(second part), while at the same time regularizing the magnitude of the
weights (third part) and the quality of the configurations $\{ \vx^{i} \}$ (last
part). The non-negative hyperparameters $\alpha,\beta,\gamma$ control the
influence of the various components.

The third part of the objective does require a more in depth explanation. In
many scenarios the user will have strong preferences about some attributes, but
will be indifferent to most of them~\cite{} \stefano{@Paolo: add refs}. The $\ell_1$ penalty is frequently
used to improve the sparsity of learned models~\cite{lasso,zhang2008,Hensinger2010}, with consequent gains
in generalization ability and efficiency, as confirmed by our empirical
findings (see Section~\ref{sec:experiments}).

The two core constraints are Equations~(\ref{eq:wyconstr}) and~(\ref{eq:wxconstr}),
which are taken directly from the discussion above. The former enforces the
correct ranking of the observed user preferences, while the latter ensures that
the generated configurations are diverse in terms of the weight vectors they
maximize. Equation~(\ref{eq:wbounds}), where the inequality is intended to be component-wise, and Eq.~(\ref{eq:xbounds})
ensure that the weights and configurations are in fact feasible, while the
remaining two guarantee the non-negativity of the slack and margin variables.
Since we require $\vw^\bot \ge (0,\ldots,0)$, Eq.~(\ref{eq:wbounds}) also enforces the weights to be non-negative.

Note that we are choosing the configurations $\{ \vx^i \}$ and the weight vectors $\{
\vw^i \}$ {\em simultaneously}. Since we maximize the margin $\mu$, the optimizer
will prefer a set of configurations $\{ \vx^{i} \}$ that partitions the weight space
roughly equally, and corresponding utility functions such that each $\vw^{i}$
lies (intuitively) close to the centre of each subregion. See
Figure~\ref{fig:setmargin} for a depiction of this intuition.\andrea{@Paolo: mmh non chiarissimo, da rivedere insieme, legenda inclusa}

\begin{figure}[t]
    \begin{center}
        \includegraphics[width=10em]{figures/setmargin}
    \end{center}
    \caption{\label{fig:setmargin} The intuition behind setwise max-margin; the red points are utility vectors $\vw^{i}$ $\vw^{j}$, the red line corresponds to the constraint $\langle \vw, \vx^{1} - \vx^{2} \rangle \ge 0$.}
\end{figure}

\paragraph{MILP Formulation.} This initial formulation is problematic to solve,
as Eq.~(\ref{eq:wxconstr}) involves quadratic terms over mixed continuous integer variables. 
Here we show how to reformulate the
problem as a mixed integer linear program (MILP). Our goal is to
replace Eq.~(\ref{eq:wxconstr}) with a set of linear constraints through
a suitable variable transformation.

In order to do so, we introduce a set of fresh variables $p^{i,j}_z$ for every
$i,j\in[k]$ and $z\in[m]$. Assuming for the time being that the new variables
do satisfy the equation $p^{i,j}_z = w^i_z x^j_z$, we rewrite the fourth
component of the objective function in terms of the new variables as:
%
$$ \gamma \sum_{i=1}^k \sum_{z=1}^m p^{i,i}_z$$
%
and, similarly, Eq.~(\ref{eq:wxconstr}) as:
%
\[ \forall \; i, j \in [k], i \neq j \;.\; \sum_{z=1}^m p^{i,i}_z - p^{i,j}_z \ge \mu \label{eq:pxconstr} \]
%
The fact that $p^{i,j}_z = w^{i}_z x^{j}_z$ is achieved by
setting the following additional constraints. We distinguish between two cases:
(i) $p^{i,i}_z$ and (ii) $p^{i,j}_z$ for $i \ne j$.  Recall that we are
maximizing the margin $\mu$. Now, due to Eq.~(\ref{eq:pxconstr}), the optimizer will
try to keep $p^{i,i}_z$ as large as possible and $p^{i,j}_z$ as small as
possible.

(Case i) We add an explicit upper bound:
%
$$ p^{i,i}_z \le \min \{ w_\text{max} x^{i}_z, w^{i}_z \} $$
%
where $w_\text{max}$ is a sufficiently large constant.
On one hand, if $x^i_z = 0$ the product $w^i_z x^i_z$ evaluates to $0$, and so does
the upper bound $w_\text{max} x^{i}_z = 0$. On the other hand, if $x^i_z=1$
then the product $w^i_z x^i_z$ amounts to $w^i_z$, while the upper
bound reduces to $\min \{ w_\text{max}, w^{i}_z \}$. By taking a sufficiently
large constant $w_\text{max}$ (e.g. $w_\text{max} := \max_z w^\top_z$) the
upper bound simplifies to $w^i_z$. Since $p^{i,i}_z$ is being maximized, in
both cases it will attain the upper bound, and thus satisfy $p^{i,j}_z = w^i_z x^i_z$.

(Case ii) We add an explicit lower bound:
%
$$ p^{i,j}_z \ge \max \{ 0, w^{i}_z - w_\text{max}(1 - x^{j}_z) \} $$
%
If $x^j_z = 1$ the lower bound simplifies to $\max \{ 0, w^{i}_z \} = w^{i}_z$,
due to the non-negativity of $w^i_z$. Otherwise, if $x^j_z = 0$
then the lower bound becomes $\max \{ 0, w^{i}_z - w_\text{max} \}$, where
the second term is at most $0$. Since $p^{i,j}_z$ is being minimized, in both
cases it will attain the lower bound, and thus satisfy $p^{i,j}_z = w^i_z
x^j_z$.\footnote{Since $\mu$ is upper-bounded by Eq.~(\ref{eq:wyconstr}), in some
cases the $p^{i,j}_z$ variables do not attain the lower bound. As a
consequence, the MILP reformulation of Eq.~(\ref{eq:wxconstr}) is a (tight)
approximation of the original one. This has no impact on the quality of the
solutions.}

Substituting the above MILP constraints into the original non-linear
formulation, we obtain the following mixed-integer linear problem:
%
{\footnotesize
\begin{align}
    \max
        & \;\; \mu - \alpha \sum_{i=1}^k \| \veps^{i} \|_1 - \beta \sum_{i=1}^k \| \vw^{i} \|_1 + \gamma \sum_{i=1}^k \sum_{z=1}^m p^{i,i}_z
        \nonumber
    \\
    \text{s.t.}
        & \;\; \forall \; i \in [k], \forall \; h \in [n] \nonumber
    \\
        & \;\; \qquad \langle \vw^{i}, \vy^{h}_+ - \vy^{h}_- \rangle \ge \mu - \varepsilon^{i}_h \nonumber
    \\
        & \;\; \forall \; i, j \in [k], i \neq j \quad \sum_{z=1}^m p^{i,i}_z - p^{i,j}_z \ge \mu
    \\
    %     & \;\; \forall \; i \in [k], \forall \; z \in [m] \nonumber
    % \\
        & \;\; \forall \; i, j \in [k], i \neq j, \forall \; z \in [m] \nonumber
    \\
        & \;\; \qquad p^{i,i}_z \le \min \{ w_\text{max} x^{i}_z, \, w^{i}_z \}
    \\
        & \;\; \qquad p^{i,j}_z \ge \max \{ 0, \, w^{i}_z - w_\text{max}(1 - x^{j}_z) \}
    \\
        & \;\; \forall \; i \in [k] \quad \vw^\bot \le \vw^{i} \le \vw^\top \label{eq:wbounds2}
    \\
        & \;\; \forall \; i \in [k] \quad \vx^{i} \in \calX_{\text{feasible}} \nonumber
    \\
        & \;\; \forall \; i \in [k] \quad \veps^{i}_h \ge 0 \nonumber
    \\
        & \;\; \mu \ge 0 \nonumber
\end{align}
}
%
which can be solved by any suitable MILP solver.

\paragraph{Set-wise max-margin.} The full {\sc SetMargin} algorithm
follows the usual preference elicitation loop. Starting from an
initially empty set of user responses $\calD$, it repeatedly solves
the MILP problem above using the set $\calD$ to enforce ranking
constraints on the weight vectors $\{\vw^i\}$. The generated
configurations $\{\vx^i\}$, which are chosen to be as good as possible
with respect to the estimated user preferences, and as diverse as
possible, are then employed to formulate a set of user queries. The
new replies are added to $\calD$ and the whole procedure is
repeated. The algorithm terminates after a fixed number of iterations,
or once another suitable condition is met. 
%\andrea{@Paolo: what termination condition for pref elicitation?}  
Termination might be left to the user to decide (see for example \cite{Reilly2007}); 
alternatively we can terminate when the difference between the utility weights is small enough.

The procedure is sketched in
Algorithm~\ref{alg:setmargin}. Note that at the end of the preference
elicitation procedure, a final recommendation is made by solving the
MILP problem for $k=1$.

\begin{algorithm}
{\footnotesize
\begin{algorithmic}[1]
    \Procedure{SetMargin}{$k, \alpha, \beta, \gamma, T$}
        \State $\calD \gets \emptyset$
        \For{$t = 1, \ldots, T$}
            \State \{$\vw^{i}, \vx^{i}\}_{i=1}^k \gets \text{{\sc Solve}}(\calD, k, \alpha, \beta, \gamma)$
            \For{$\vx^{i},\vx^{j} \in \{ \vx^{1}, \ldots, \vx^{k} \} \; \text{{\bf s.t.}} \; i < j$}
                \State $\calD \gets \calD \cup \text{{\sc QueryUser}}(\vx^{i},\vx^{j})$
            \EndFor
        \EndFor
        \State $\vw^*, \vx^* \gets \text{{\sc Solve}}(\calD, 1, \alpha, \beta, \gamma)$
        \State ${\bf return}\; \vw^*, \vx^*$
    \EndProcedure
\end{algorithmic}
}
\caption{\label{alg:setmargin} The {\sc SetMargin} algorithm. Here $k$ is the
set size, $\alpha,\beta,\gamma$ are the hyperparameters, and $T$ is the maximum
number of iterations. The values of $\calX_\text{feasible}$, $\vw^\top$ and
$\vw^\bot$ are left implicit.}
\end{algorithm}

\paragraph{Linearly dependent real attributes.} In many domains of interest,
items are composed of both Boolean and real-valued attributes, where the latter
depend linearly  on the former. This is for instance the case for the price,
weight and power consumption of a laptop model, which depend linearly on the
choice of components.
%
In this setting, item configurations are composed of two parts: $\vx =
(\vx_B;\vx_R)$, where $\vx_B$ is Boolean and $\vx_R$ is real-valued, and the
relation between the two is entirely described by an appropriately sized
non-negative cost matrix $C$, such that $\vx_R = C \vx_B$. It is
straightforward to extend the MILP formulation to this setting, as follows.

First, we rewrite the weight vector as $\vw = (\vw_B;\vw_R)$. The utility
becomes:
%
$$ \langle \vw, \vx \rangle = \langle \vw_B, \vx_B \rangle + \langle \vw_R, C \vx_B \rangle = \langle \vw_B + C' \vw_R, \vx_B \rangle $$
%
The generalized problem is obtained by substituting $\vw^i$ with $\vv^i :=
\vw_B^i + C' \vw_R^i$.  All constraints remain the same. The only notable
change occurs in Eq.~(\ref{eq:wbounds2}), which becomes:
%
$$ \forall \; i \in [k] \;.\; (\vw_B^\bot + C' \vw_R^\bot) \le \vv^i \le (\vw_B^\top + C' \vw_R^\top)$$
%
As can be seen, non-negativity of $C$ is required for the weights $\{\vv^i\}$
to be non-negative.

\section{Experiments}
\label{sec:experiments}

We implemented the {\sc SetMargin} algorithm using Python, leveraging Gurobi
6.5.0 for solving the core MILP problem. Both the {\sc SetMargin} source code
and the full experimental setup are available at \url{https://db.tt/oqY62odW}.

We compare {\sc SetMargin} against the following competitive Bayesian baselines:
% and \cite{viappiani2010optimal}.


\paolo{Se bisogno di spazio, posso accorciare la descrizione.}
\begin{itemize}
 \item The Bayesian approach from \cite{guo2010real}, selecting queries according to 
 {\em restricted uninformed VOI}, an heuristic approximation of value-of-information a query, and performing inference using  TrueSkill$^{TM}$ \cite{HerbrichMG06} (an inference scheme based on expectation propagation \cite{Minka01}).
 \item The Bayesian framework of \cite{viappiani2010optimal}, using Monte Carlo methods for Bayesian inference and asking choice queries (asking the user to select its preferred item among a set of diplayed ones); the next query is computed by performing a greedy optimization of {\em Expected Utility of a Selection} (hereafter just called EUS), a submodular quantity that can be used as a proxy for value of information (giving strong approximate guarantees).
 \item {\em Query Iteration} (referred as QI below), also from \cite{viappiani2010optimal}, an even faster query selection method based on sampling a set of utility vectors, selecting the items that maximize utility for each of the vector, forming a first proposal for a query set. Then, a new set is computed by considering the optimal items in the associated  beliefs, and the process is repeated until convergence.
\end{itemize}


We adopt the {\em indifference-augmented} Bradley-Terry user response
model introduced in~\cite{guo2010real}. According to the classical
(without indifference) Bradley-Terry model~\cite{BraTer52}, when queried about a pair
of configurations, the probability that a user will prefer
configuration $\vx^i$ over the alternative $\vx^j$ amounts to:
%
$$ (1 + \exp(-\lambda_1 \langle\vw,\vx^i - \vx^j\rangle))^{-1} $$
%
where $\vw$ is the weight vector of the true underlying user utility.
In other words, the probability grows with the difference between the
utilities of the two items. Support for indifference has been
introduced in~\cite{guo2010real} by postulating that the probability
of the user being indifferent about the two configurations depends on
how close their utilities are, as in:
%
$$ \exp(-\lambda_2 |\langle\vw,\vx^i - \vx^j\rangle|) $$
%
The parameters $\lambda_1$ and $\lambda_2$ were set to one for all
simulations, as in~\cite{guo2010real}.

In all experiments {\sc SetMargin} uses an internal 5-fold cross-validation procedure to
update the hyperparameters $\alpha$, $\beta$, and $\gamma$ after every 5
iterations. The hyperparameters are chosen as to minimize the ranking loss over
the user responses collected so far. $\alpha$ is taken in $\{20, 10, 5, 1\}$,
while $\beta$ and $\gamma$ are taken in $\{10, 1, 0.1, 0.001\}$.\footnote{Note
that $\alpha$ can not be taken to be less than $1$, as in this case, the
objective can be increased arbitrarily while keeping the right-hand side of
Eq.~(\ref{eq:wyconstr}) constant, rendering the problem unbounded.}

\paragraph{Synthetic Dataset.} Following the experimental protocol
in~\cite{guo2010real} and \cite{viappiani2010optimal}, in the first
experiment we evaluate the behavior of the proposed method in an
artificial setting with increasingly complex problems. We developed
synthetic datasets with $r$ attributes, for increasing values of $r$.
Each attribute takes one of $r$ possible values, so that the one-hot
encoding of attributes results in $m=r^2$ features. In terms of space
of configurations, for $r=3$ the synthetic dataset corresponds to 
$\calX_\text{feasible} = [3] \times [3] \times [3]$, for $r=4$ to
$\calX_\text{feasible} = [4] \times [4] \times [4] \times [4]$, and so on. The
cardinality of $\calX_\text{feasible}$ is $r^r$, and grows (super)
exponentially with $r$.
% We developed
% seven synthetic datasets: each dataset involves $m=2,\ldots,7$
% attributes, where each attribute takes one of $m$ possible
% values. More explicitly, for $m=2$ the synthetic dataset is
% $\calX_\text{feasible} = [2] \times [2]$, for $m=3$ to
% $\calX_\text{feasible} = [3] \times [3] \times [3]$, and so on. The
% cardinality of $\calX_\text{feasible}$ is $m^m$, and grows (super)
% exponentially with $m$. 
For $r=3$, the dataset is comparable to the synthetic one used
in~\cite{guo2010real} and~\cite{viappiani2010optimal}, which have
three attributes with 2, 2 and 5 values respectively, for a total of
20 feasible configurations.  For larger $r$ the size of the space
grows much larger than the one typically used in the Bayesian
preference elicitation literature, and as such represents a good test
bed for comparing the scalability of the various methods. The feasible
configuration space was encoded in {\sc SetMargin} through appropriate
MILP constraints, while the other methods require all datasets to be
explicitly grounded.

Users were simulated by drawing $20$ random utility vectors from each of four
different distributions. The first two mimic those used
in~\cite{guo2010real}\footnote{The normal distribution reported
in~\cite{guo2010real} differs slightly from the one implemented in the code of
their experimental setting. 
In our experiments we use the latter.}:
(1) a uniform distribution over $[1, 100]$ for each individual weight, and (2)
a normal distribution with mean $25$ and %covariance
standard deviation $\frac{25}{3}$ (each attribute is sample i.i.d).  
We further produced two novel
{\em sparse} sets of weight vectors by setting to zero $80\%$ of the entries of the
vectors sampled in the uniform and normal settings uniformly at random. 
All methods were evaluated on the very same weight vectors. All users had
a budget of 100 iterations; for {\sc SetMargin} we used a $0.01$
threshold on the utility loss for early stopping (that does not affect the
cross-validation procedure).
The Bayesian methods can use the estimated loss to decide when to stop (the expectation
of the utility loss with respect to the current probabilistic belief)
\footnote{In our experiments, we left the Bayesian methods to run the full amount of iterations,
even when the estimated loss was very low.}.

\andrea{give names to competitors}

%\onecolumn

\begin{figure*}[h!]
    \centering
    {\footnotesize
    \begin{tabular}{cccc}
        \hline
        {\sc synthetic 3 loss} & {\sc synthetic 3 time} & {\sc synthetic 4 loss} & {\sc synthetic 4 time}
        \\
        \hline \hline
        \multicolumn{4}{c}{{\sc Uniform}}
        \\
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_uniform_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_uniform_per_iter_time} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_uniform_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_uniform_per_iter_time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Normal}}
        \\
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_normal_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_normal_per_iter_time} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_normal_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_normal_per_iter_time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Sparse Uniform}}
        \\
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_uniform_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_uniform_sparse_per_iter_time} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_uniform_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_uniform_sparse_per_iter_time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc Sparse Normal}}
        \\
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_normal_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_3_normal_sparse_per_iter_time} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_normal_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_others_4_normal_sparse_per_iter_time}
        \\
        \hline
    \end{tabular}
    }
    \caption{\label{fig:comparison} Comparison between {\sc SetMargin}
      (orange), Guo (blue), Viappiani QI (green) and Viappiani EUS
      (gray) on the $r=3$ (left) and $r=4$ (right) datasets. Each row
      represents a different distribution for sampling the underlying
      user utility.  The number of iterations is plotted against the
      utility loss (first and third columns) and the cumulative time
      (second and fourth columns).  Thick lines indicate median values
      over users, while standard deviations are shown as shaded
      areas.}
\end{figure*}


%\twocolumn

In Figure~\ref{fig:comparison} we report solution quality and timing
values for increasing number of collected user responses, for the
different competitors on each of the four different utility vector
distributions. Solution quality is measured in terms of utility loss:
%
$$ \max_{\vx\in\calX_\text{feasible}} \left( u(\vx) - u(\vx^*) \right) $$
%
where $u(\cdot)$ is the true unknown user utility, and $\vx^*$ is the
solution recommended to the user after the elicitation phase (see
Algorithm~\ref{alg:setmargin}). Computational cost is measured in
terms of cumulative time. Given that Guo and Viappiani (both QI and
EUS) are single-threaded, we disabled multi-threading when running our
algorithm in these comparisons. All experiments were run on a 2.8 GHz Intel
Xeon CPU with 8 cores and 32 GiB of RAM.
In all figures, thick lines indicate median values over the different
users, shaded areas indicate standard deviations. Our {\sc SetMargin}
algorithm for $k=2$ is reported in orange, Guo in blue, Viappiani QI
in green and Viappiani EUS in gray. For all algorithms, one iteration
corresponds to a single pairwise query to the user.  Results for $r=3$
and $r=4$ are reported.  For dense weight vector distributions (first
two rows), our approach achieves results which are indistinguishable
from the competitors in a fraction of their time.  Indeed, all
Bayesian approaches become quickly intractable for growing values of $r$,
%cannot scale over $r=4$ (for $r=5$, Guo did not
%finish a single user after 24 hours for, Viappiani QI takes 20 minutes
%per user), \andrea{20 minuti mi paiono pochi, sei sicuro?}  
while our algorithm can easily scale to much larger datasets, as will
be shown later on. For sparse weight vector distributions (last two
rows) our approach, in addition to being substantially faster on each
iteration, requires less queries in order to reach optimal
solutions. This is an expected result as the sparsification norm in
our formulation ($\| \vw \|_1$) is enforcing sparsity in the weights, 
while none of the other approaches is %explicitly 
designed to favour sparse functions.


% Guo e' piantato al primo utente da tre giorni su synthetic 5.
% Paolo procede su S-5 da qualche ora (~8) (1290s su synthetic-5
% uniforme per completamento di un utente).

%\stefano{@Paolo: varianza tempi?}

\begin{figure*}[h!]
    \centering
    {\footnotesize
    \begin{tabular}{cccc}
        \hline
        \multicolumn{2}{c}{{\sc synthetic 4}} &
        \multicolumn{2}{c}{{\sc synthetic 5}}
        \\
        {\sc loss per iter.} & {\sc loss per query} & {\sc loss per iter.} & {\sc loss per query}
        \\
        \hline \hline
        \multicolumn{4}{c}{{\sc uniform}}
        \\
        \includegraphics[width=10em]{figures/synthetic_vs_self_4_uniform_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_self_4_uniform_per_query_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_self_5_uniform_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_self_5_uniform_per_query_loss}
        \\
        \hline
        \multicolumn{4}{c}{{\sc sparse normal}}
        \\
        \includegraphics[width=10em]{figures/synthetic_vs_self_4_normal_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_self_4_normal_sparse_per_query_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_self_5_normal_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/synthetic_vs_self_5_normal_sparse_per_query_loss}
        \\
        \hline
     \end{tabular}
    }
    \caption{\label{fig:selfcomparison} Comparison for {\sc SetMargin}
      with $k=2,3,4$, in orange, blue and green respectively for the
      $r=4$ (left) and $r=5$ (right) datasets using uniform (top row) and sparse normal (bottom row) distributions. Median and standard deviation utility loss values are reported for increasing number of iterations ($1^{st}$ and $3^{rd}$ columns) and pairwise queries ($2^{nd}$ and $4^{th}$ columns).}
\end{figure*}


In order to study the effect of increasing the number of weight
vectors in our formulation, we also ran {\sc SetMargin} varying the
parameter $k$. Figure~\ref{fig:selfcomparison} reports utility loss
results on $r=4$ and $r=5$ datasets for the uniform and sparse normal
distributions\footnote{We picked the most difficult dense distribution
  (uniform) and the simplest sparse distribution (normal) to provide
  the broadest possible picture, as space constraints prevent us from
  including all results. Results for the other distributions are
  however qualitative similar to the ones reported.}, for $k=2$
(orange), $k=3$ (blue) and $k=4$ (green). The first and third columns
report results in terms of number of iterations. It can be seen that
increasing the number of weight vectors tends to favour earlier
convergence, especially for the more complex dataset ($r=5$). However,
as in each iteration the user is asked to compare $k$ items, different
values of $k$ imply a different cognitive effort for the user. The
second and fourth columns report results in terms of number of
queries, where we count all $k \choose 2$ pairs of queries when
comparing $k$ items. In this case, $k=2$ seems to be the best
option. The cognitive cost for the user will likely lay in between
these two extremes, but formalizing this concept in an efficient query
ordering strategy needs to face the effect of noise.  A modified
sorting algorithm asking only $O(k\log k)$ queries to the user
resulted in a performance worsening, likely because of a cascading
effect of inconsistence feedback.

% \paragraph{Cognitive effort.} Contrarily to most other preference elicitation
% methods, which generate a single candidate option per iteration, {\sc
% SetMargin} constructs a whole {\em set} of options. We thus can not leverage
% standard query selection strategies \stefano{which ones?}. 

% The simplest solution is to query the user about all $k \choose 2$ pairs of
% configurations in $\{\vx^i\}$. Since $k$ is a small constant, the resulting
% number of queries does not grow large in practice.  An appealing alternative
% involves using a modified sorting algorithm, such as merge-sort, to order the
% set $\{\vx^i\}$ by asking only $O(n\log n)$ queries to the user. However, this
% approach is very susceptible to noise: a single inconsistent user response may
% affect all successive comparisons, leading to a cascading effect. While more
% robust strategies may be conceived, empirically we found that the simpler
% quadratic scheme tends to work reasonably well.

%\paolo{Maybe a plot of an experiment with increased noise in user response? (for example, $\beta=0.1$ instead of $1$.}


\paragraph{Constructive dataset.} Next, we tested {\sc SetMargin} on a truly
constructive setting. We developed a constructive version of the PC dataset
used in~\cite{guo2010real}: instead of explicitly enumerating all possible PC
items, we defined the set of feasible configurations with MILP constraints.

A PC configurations is defined by eight attributes: computer type (laptop,
desktop, or tower), manufacturer (8 choices), CPU model (37), monitor size (8), RAM amount (10), storage (10)
size, and price.
%See Table~\ref{tab:pcdataset} for an overivew of the attributes.
The price attribute is defined as a linear combination of the other
attributes: this is a fair modeling choice, as often the price of a PC is
well approximated by the sum of the price of its components plus a bias due to
branding.
%
Interactions between attributes are expressed as Horn clauses. An example
constraint might look like this: ``if the manufacturer is Apple, then the
CPU must be either a PowerPC G3 or a PowerPC G4''\footnote{Despite the components
included in the dataset, which are a bit outdated, the dataset itself is pretty
realistic.}, which can be encoded
into MILP form as
%
$ (1 - x_\text{Apple}) + x_\text{G3} + x_\text{G4} \ge 1 $.
%
Note that mutual exclusivity between all binary variables of the
one-hot encoding of an attribute ensures that only one of
$x_\text{G3}$ and $x_\text{G4}$ can be 1.  The dataset includes
constraints between the following attributes: manufacturer $\to$ type,
manufacturer $\to$ CPU, type $\to$ RAM amount, type $\to$ storage
size, type $\to$ monitor size, for 16 Horn constraints total. We do
not report the full list due to space limitations. Note that the
search space is of the order of hundreds of thousands of candidate
configurations, and is far beyond reach of existing Bayesian
approaches.

Figure~\ref{fig:pc} reports results of {\sc SetMargin} for $k=2$
(red), $k=3$ (blue) and $k=4$ (green) using the sparse uniform (top
row) and sparse normal (bottom row) distributions. The first and third
column report utility loss for increasing number of iterations and
queries respectively, showing a behaviour which is similar to the one
in Figure~\ref{fig:selfcomparison}. Overall, between 50 and 70 queries
on average are needed in order to find out a solution which is only
10\% worse than the optimal one, out of the more than 700,000
thousands available. Note that a vendor may ensure a considerably smaller
number of queries by cleverly constraining the feasible configuration space;
since our primary aim is benchmarking, we chose not to pursue this direction
further.
The second and fourth
columns report cumulative times. Note that in some cases, standard
deviations have a bump; this is due to cases in which some of the
hyperparameters of the internal cross validation result in
ill-conditioned optimization problems which are hard to solve. These
exceptions can be easily dealt with by setting an appropriate timeout
on the cross validation without affecting the results, as these
hyperparameters typically end up having bad performance and being
discarded.

% \begin{table}
%     \centering
%     \begin{tabular}{ccc}
%         {\bf Attribute} & {\bf Type} & {\bf Values} \\
%         \hline \hline
%         Type & discrete & 3 \\
%         Manufacturer & discrete & 8 \\
%         CPU model & discrete & 37 \\
%         RAM amount & discrete & 10 \\
%         HD size & discrete & 10 \\
%         Monitor size & discrete & 8 \\
%         Price & continuous & --
%     \end{tabular}
%     \caption{\label{tab:pcdataset} Statistics for the PC dataset.}
% \end{table}


\section{Conclusion}
\label{sec:conclusions}

We presented a max-margin approach for efficient preference
elicitation in large configuration spaces. Our approach relies on an
extension of max-margin learning to sets of hyperplanes, and is
effective in the generation of a diverse set of items that can be used
to ask informative queries to the user.  The main advantages of our
elicitation method are 1) its ability to elicit preferences and
provide recommendations in large configuration problems 2) its
robustness with respect to erroneous feedback and 3) its ability to
encourage sparse utility functions. Experimental comparisons against
state-of-the-art Bayesian preference elicitation strategies confirm
its substantial computational advantages. For sparse utility
functions, the method compares favourably also in terms of the number
of queries asked to the user.

\paolo{any idea about possible future works?}
% FUTURE WORKS

%\section*{Acknowledgments}
%WRITEME

\bibliographystyle{named}
\bibliography{ijcai16}


% times for the figure above
% synthetic_vs_self_4_normal_sparse_per_iter_time
% synthetic_vs_self_4_normal_sparse_per_query_time
% synthetic_vs_self_4_uniform_per_iter_time
% synthetic_vs_self_4_uniform_per_query_time
% synthetic_vs_self_5_normal_sparse_per_iter_time
% synthetic_vs_self_5_normal_sparse_per_query_time
% synthetic_vs_self_5_uniform_per_iter_time
% synthetic_vs_self_5_uniform_per_query_time

\begin{figure*}
    \centering
    {\footnotesize
    \begin{tabular}{cccc}
        \hline
        \multicolumn{2}{c}{{\sc loss/time per iter.}} &
        \multicolumn{2}{c}{{\sc loss/time per query}}
        \\
        \multicolumn{4}{c}{{\sc sparse uniform}}
        \\
        \includegraphics[width=10em]{figures/pc_with_costs_uniform_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/pc_with_costs_uniform_sparse_per_iter_time} &
        \includegraphics[width=10em]{figures/pc_with_costs_uniform_sparse_per_query_loss} &
        \includegraphics[width=10em]{figures/pc_with_costs_uniform_sparse_per_query_time}
        \\
        \hline
        \multicolumn{4}{c}{{\sc sparse normal}}
        \\
        \includegraphics[width=10em]{figures/pc_with_costs_normal_sparse_per_iter_loss} &
        \includegraphics[width=10em]{figures/pc_with_costs_normal_sparse_per_iter_time} &
        \includegraphics[width=10em]{figures/pc_with_costs_normal_sparse_per_query_loss} &
        \includegraphics[width=10em]{figures/pc_with_costs_normal_sparse_per_query_time}
        \\
        \hline
    \end{tabular}
    }
    \caption{\label{fig:pc} Results for {\sc SetMargin} on the constructive PC
    dataset.}
\end{figure*}


\end{document}
